{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EltwXFS-h0N"
   },
   "source": [
    "# Baseline Code for Deepfake Detection\n",
    "\n",
    "\n",
    "By Dongmin Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vfYll4q9Dqj"
   },
   "source": [
    "## Data Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2574,
     "status": "ok",
     "timestamp": 1594861880337,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "AkbZHQ3w_3TH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "physical_devices = tf.config.experimental.get_visible_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COfNhpEv6u5S"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGR = lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "TOTAL_DATA_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9626,
     "status": "ok",
     "timestamp": 1594861887408,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "TYD8hU74FOKe"
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20, \n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest',\n",
    "    validation_split = VALID_RATIO,\n",
    ")\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **data_gen_args,\n",
    "    preprocessing_function = BGR\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    preprocessing_function = BGR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM DIR\n",
      "REAL:  10000\n",
      "FAKE:  10000\n",
      "TOTAL:  20000\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "#path = \"/media/data1/hsm/FACE_FORENSICS_C40/DATA_FRAMES/\"\n",
    "path = \"./TK_diff\"\n",
    "real_data_dir = os.path.join(path, 'REAL')\n",
    "fake_data_dir = os.path.join(path, 'FAKE', 'NeuralTextures')\n",
    "\n",
    "real_filenames = np.array([os.path.join('REAL', f) for f in os.listdir(real_data_dir)])\n",
    "fake_filenames = np.array([os.path.join('FAKE', 'NeuralTextures', f) for f in os.listdir(fake_data_dir)])\n",
    "\n",
    "print(\"FROM DIR\")\n",
    "print(\"REAL: \", len(real_filenames))\n",
    "print(\"FAKE: \", len(fake_filenames))\n",
    "print(\"TOTAL: \", len(real_filenames) + len(fake_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling\n",
    "real_filenames = np.random.choice(real_filenames, TOTAL_DATA_SIZE//2, replace = False).tolist()\n",
    "fake_filenames = np.random.choice(fake_filenames, TOTAL_DATA_SIZE//2, replace = False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIM SIZE\n",
      "REAL:  10000\n",
      "FAKE:  10000\n",
      "TOTAL:  20000\n",
      "TRAIN:  16200 VALIDATION:  1800 TEST:  2000\n"
     ]
    }
   ],
   "source": [
    "print(\"TRIM SIZE\")\n",
    "print(\"REAL: \", len(real_filenames))\n",
    "print(\"FAKE: \", len(fake_filenames))\n",
    "print(\"TOTAL: \", len(real_filenames) + len(fake_filenames))\n",
    "\n",
    "total_length = len(real_filenames) + len(fake_filenames)\n",
    "\n",
    "test_length = int(total_length * TEST_RATIO)\n",
    "validation_length = int((total_length-test_length) * VALID_RATIO)\n",
    "train_length = total_length - validation_length - test_length\n",
    "\n",
    "print(\"TRAIN: \", train_length, \"VALIDATION: \", validation_length, \"TEST: \", test_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_filenames_test = real_filenames[:test_length//2]\n",
    "fake_filenames_test = fake_filenames[:test_length//2]\n",
    "real_filenames = real_filenames[test_length//2:]\n",
    "fake_filenames = fake_filenames[test_length//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_categories_test = []\n",
    "for filename in real_filenames_test:\n",
    "    real_categories_test.append('0')\n",
    "        \n",
    "real_testdata = pd.DataFrame({'filename' : real_filenames_test, 'label' : real_categories_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_categories_test = []\n",
    "for filename in fake_filenames_test:\n",
    "    fake_categories_test.append('1')\n",
    "\n",
    "fake_testdata = pd.DataFrame({'filename' : fake_filenames_test, 'label' : fake_categories_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([real_testdata, fake_testdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real : 0, fake : 1\n",
    "categories = []\n",
    "for filename in real_filenames:\n",
    "    categories.append('0')\n",
    "    \n",
    "for filename in fake_filenames:\n",
    "    categories.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'filename' : real_filenames + fake_filenames, 'label' : categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/16__podium_speech_happy_frame1145.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/11__talking_against_wall_frame30.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/133_frame456.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/05__talking_against_wall_frame300.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/672_frame354.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>FAKE/NeuralTextures/211_177_frame120.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>FAKE/NeuralTextures/727_729_frame370.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>FAKE/NeuralTextures/314_347_frame318.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>FAKE/NeuralTextures/546_621_frame210.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>FAKE/NeuralTextures/743_750_frame144.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename label\n",
       "0      REAL/16__podium_speech_happy_frame1145.jpg     0\n",
       "1       REAL/11__talking_against_wall_frame30.jpg     0\n",
       "2                           REAL/133_frame456.jpg     0\n",
       "3      REAL/05__talking_against_wall_frame300.jpg     0\n",
       "4                           REAL/672_frame354.jpg     0\n",
       "...                                           ...   ...\n",
       "17995    FAKE/NeuralTextures/211_177_frame120.jpg     1\n",
       "17996    FAKE/NeuralTextures/727_729_frame370.jpg     1\n",
       "17997    FAKE/NeuralTextures/314_347_frame318.jpg     1\n",
       "17998    FAKE/NeuralTextures/546_621_frame210.jpg     1\n",
       "17999    FAKE/NeuralTextures/743_750_frame144.jpg     1\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[np.random.RandomState(seed = 42).permutation(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>REAL/794_frame430.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>REAL/540_frame170.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>FAKE/NeuralTextures/104_126_frame78.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>REAL/01__kitchen_still_frame250.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>REAL/241_frame210.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>FAKE/NeuralTextures/234_187_frame102.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>FAKE/NeuralTextures/118_120_frame125.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>REAL/744_frame84.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>REAL/074_frame35.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>FAKE/NeuralTextures/544_532_frame270.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename label\n",
       "2574                      REAL/794_frame430.jpg     0\n",
       "7496                      REAL/540_frame170.jpg     0\n",
       "9210    FAKE/NeuralTextures/104_126_frame78.jpg     1\n",
       "5456        REAL/01__kitchen_still_frame250.jpg     0\n",
       "736                       REAL/241_frame210.jpg     0\n",
       "...                                         ...   ...\n",
       "11284  FAKE/NeuralTextures/234_187_frame102.jpg     1\n",
       "11964  FAKE/NeuralTextures/118_120_frame125.jpg     1\n",
       "5390                       REAL/744_frame84.jpg     0\n",
       "860                        REAL/074_frame35.jpg     0\n",
       "15795  FAKE/NeuralTextures/544_532_frame270.jpg     1\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/07__talking_angry_couch_frame1500.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/385_frame72.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/06__walk_down_hall_angry_frame20.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/825_frame420.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/994_frame25.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>FAKE/NeuralTextures/949_868_frame72.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>FAKE/NeuralTextures/579_701_frame96.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>FAKE/NeuralTextures/271_264_frame90.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>FAKE/NeuralTextures/712_716_frame340.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>FAKE/NeuralTextures/359_317_frame294.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename label\n",
       "0    REAL/07__talking_angry_couch_frame1500.jpg     0\n",
       "1                          REAL/385_frame72.jpg     0\n",
       "2     REAL/06__walk_down_hall_angry_frame20.jpg     0\n",
       "3                         REAL/825_frame420.jpg     0\n",
       "4                          REAL/994_frame25.jpg     0\n",
       "..                                          ...   ...\n",
       "995     FAKE/NeuralTextures/949_868_frame72.jpg     1\n",
       "996     FAKE/NeuralTextures/579_701_frame96.jpg     1\n",
       "997     FAKE/NeuralTextures/271_264_frame90.jpg     1\n",
       "998    FAKE/NeuralTextures/712_716_frame340.jpg     1\n",
       "999    FAKE/NeuralTextures/359_317_frame294.jpg     1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1000\n",
       "1    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.groupby(['label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44421,
     "status": "ok",
     "timestamp": 1594861922212,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "JfDhCEOCHMP9",
    "outputId": "bf643961-e321-433e-84f8-7f793bd2efda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16200 validated image filenames belonging to 2 classes.\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "Found 2000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True,\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True,\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53852,
     "status": "ok",
     "timestamp": 1594861931663,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "Q7lrrsvnh0FO",
    "outputId": "763103a8-abec-4e65-91c0-fe6e1a91cf63"
   },
   "outputs": [],
   "source": [
    "# import available models for training\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Dropout\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53849,
     "status": "ok",
     "timestamp": 1594861931664,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "h_qQl7mYM_4H"
   },
   "outputs": [],
   "source": [
    "def setupmodel():\n",
    "    input_tensor = Input(shape = (256,256,3))\n",
    "\n",
    "    base_model = Xception(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_tensor = input_tensor\n",
    "    )\n",
    "    # Setup\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation = \"relu\")(x)\n",
    "    prediction = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # model return\n",
    "    model = Model(base_model.input, prediction)\n",
    "\n",
    "    # trainable\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57132,
     "status": "ok",
     "timestamp": 1594861934952,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "W72UW_JAOqIL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dongmin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = setupmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57125,
     "status": "ok",
     "timestamp": 1594861934955,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "w1aKA6TGPYQJ",
    "outputId": "d713b6a3-c474-4ff3-db93-246221cd12ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 63, 63, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 63, 63, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 63, 63, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 131072)       0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          33554688    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 54,416,425\n",
      "Trainable params: 54,361,897\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57122,
     "status": "ok",
     "timestamp": 1594861934956,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "g2uCmYuC_QFB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(tf.keras.callbacks.Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57119,
     "status": "ok",
     "timestamp": 1594861934957,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "Gg-pDKlNjjf1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, validation_generator, test_generator, optimizer):\n",
    "    # checkpointing\n",
    "    filename = 'checkpoint-TK_diff-smalldata.h5'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                        filename, \n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,           \n",
    "                        save_best_only=True,\n",
    "                        mode='auto'\n",
    "                )\n",
    "    # early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # Cyclic Learning Rate\n",
    "    clr = CyclicLR(\n",
    "        base_lr=1e-3,#0.001, \n",
    "        max_lr=7e-3,#0.007,\n",
    "        step_size=300., \n",
    "        mode='exp_range',\n",
    "        gamma=0.99994\n",
    "    )\n",
    "    \n",
    "    # compile\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    # train\n",
    "    print(\"== Start Training ==\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = train_length // BATCH_SIZE, \n",
    "        epochs = EPOCHS,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = validation_length // BATCH_SIZE,\n",
    "        callbacks=[checkpoint, clr],\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8202582,
     "status": "ok",
     "timestamp": 1594870080429,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "JzhaoVTjPPw-",
    "outputId": "44580b4c-b6d8-45bb-c65e-ecf7a1ae9c12",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Start Training ==\n",
      "Epoch 1/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.7499 - accuracy: 0.5007\n",
      "Epoch 00001: val_loss improved from inf to 0.68830, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 394s 779ms/step - loss: 0.7498 - accuracy: 0.5008 - val_loss: 0.6883 - val_accuracy: 0.5234\n",
      "Epoch 2/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.5258\n",
      "Epoch 00002: val_loss did not improve from 0.68830\n",
      "506/506 [==============================] - 328s 649ms/step - loss: 0.6870 - accuracy: 0.5258 - val_loss: 0.7183 - val_accuracy: 0.5184\n",
      "Epoch 3/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6871 - accuracy: 0.5174\n",
      "Epoch 00003: val_loss did not improve from 0.68830\n",
      "506/506 [==============================] - 328s 648ms/step - loss: 0.6871 - accuracy: 0.5174 - val_loss: 0.6930 - val_accuracy: 0.4894\n",
      "Epoch 4/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6887 - accuracy: 0.5201\n",
      "Epoch 00004: val_loss did not improve from 0.68830\n",
      "506/506 [==============================] - 315s 623ms/step - loss: 0.6887 - accuracy: 0.5203 - val_loss: 0.7203 - val_accuracy: 0.5022\n",
      "Epoch 5/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5022\n",
      "Epoch 00005: val_loss did not improve from 0.68830\n",
      "506/506 [==============================] - 314s 621ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6915 - val_accuracy: 0.5106\n",
      "Epoch 6/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.5271\n",
      "Epoch 00006: val_loss improved from 0.68830 to 0.68328, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 315s 623ms/step - loss: 0.6854 - accuracy: 0.5270 - val_loss: 0.6833 - val_accuracy: 0.5251\n",
      "Epoch 7/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.5283\n",
      "Epoch 00007: val_loss did not improve from 0.68328\n",
      "506/506 [==============================] - 329s 651ms/step - loss: 0.6823 - accuracy: 0.5284 - val_loss: 0.6995 - val_accuracy: 0.5206\n",
      "Epoch 8/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.5395\n",
      "Epoch 00008: val_loss improved from 0.68328 to 0.67874, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 329s 651ms/step - loss: 0.6812 - accuracy: 0.5395 - val_loss: 0.6787 - val_accuracy: 0.5257\n",
      "Epoch 9/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6800 - accuracy: 0.5425\n",
      "Epoch 00009: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 328s 649ms/step - loss: 0.6800 - accuracy: 0.5423 - val_loss: 0.7085 - val_accuracy: 0.5017\n",
      "Epoch 10/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5028\n",
      "Epoch 00010: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 327s 647ms/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6940 - val_accuracy: 0.4994\n",
      "Epoch 11/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.5164\n",
      "Epoch 00011: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 327s 645ms/step - loss: 0.6898 - accuracy: 0.5161 - val_loss: 0.6910 - val_accuracy: 0.5173\n",
      "Epoch 12/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6855 - accuracy: 0.5312\n",
      "Epoch 00012: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 326s 644ms/step - loss: 0.6854 - accuracy: 0.5312 - val_loss: 0.6849 - val_accuracy: 0.5212\n",
      "Epoch 13/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6991 - accuracy: 0.5204\n",
      "Epoch 00013: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 316s 624ms/step - loss: 0.6991 - accuracy: 0.5203 - val_loss: 0.6935 - val_accuracy: 0.5006\n",
      "Epoch 14/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5012\n",
      "Epoch 00014: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 323s 638ms/step - loss: 0.6935 - accuracy: 0.5010 - val_loss: 0.6927 - val_accuracy: 0.4978\n",
      "Epoch 15/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5058\n",
      "Epoch 00015: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 324s 641ms/step - loss: 0.6931 - accuracy: 0.5057 - val_loss: 0.6922 - val_accuracy: 0.5128\n",
      "Epoch 16/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5053\n",
      "Epoch 00016: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.6929 - accuracy: 0.5053 - val_loss: 0.6926 - val_accuracy: 0.5039\n",
      "Epoch 17/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6965 - accuracy: 0.5147\n",
      "Epoch 00017: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 322s 636ms/step - loss: 0.6965 - accuracy: 0.5143 - val_loss: 0.6926 - val_accuracy: 0.5084\n",
      "Epoch 18/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5149\n",
      "Epoch 00018: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 323s 637ms/step - loss: 0.6925 - accuracy: 0.5150 - val_loss: 0.6927 - val_accuracy: 0.5134\n",
      "Epoch 19/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5147\n",
      "Epoch 00019: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 319s 630ms/step - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.6925 - val_accuracy: 0.5095\n",
      "Epoch 20/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5088\n",
      "Epoch 00020: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 633ms/step - loss: 0.6934 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5033\n",
      "Epoch 21/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.4932\n",
      "Epoch 00021: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 323s 639ms/step - loss: 0.6937 - accuracy: 0.4932 - val_loss: 0.6934 - val_accuracy: 0.4967\n",
      "Epoch 22/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.4983\n",
      "Epoch 00022: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 326s 643ms/step - loss: 0.6934 - accuracy: 0.4983 - val_loss: 0.6934 - val_accuracy: 0.4961\n",
      "Epoch 23/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 00023: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 633ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6930 - val_accuracy: 0.5033\n",
      "Epoch 24/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5100\n",
      "Epoch 00024: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 633ms/step - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.4978\n",
      "Epoch 25/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6942 - accuracy: 0.5104\n",
      "Epoch 00025: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 324s 639ms/step - loss: 0.6942 - accuracy: 0.5104 - val_loss: 0.6930 - val_accuracy: 0.5151\n",
      "Epoch 26/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5148\n",
      "Epoch 00026: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 633ms/step - loss: 0.6930 - accuracy: 0.5148 - val_loss: 0.6925 - val_accuracy: 0.5112\n",
      "Epoch 27/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.5154\n",
      "Epoch 00027: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 318s 628ms/step - loss: 0.6921 - accuracy: 0.5153 - val_loss: 0.6911 - val_accuracy: 0.5223\n",
      "Epoch 28/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5245\n",
      "Epoch 00028: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 321s 634ms/step - loss: 0.6927 - accuracy: 0.5245 - val_loss: 0.6929 - val_accuracy: 0.5028\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/506 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5064\n",
      "Epoch 00029: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 632ms/step - loss: 0.6932 - accuracy: 0.5065 - val_loss: 0.6932 - val_accuracy: 0.5100\n",
      "Epoch 30/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5117\n",
      "Epoch 00030: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 318s 628ms/step - loss: 0.6931 - accuracy: 0.5114 - val_loss: 0.6925 - val_accuracy: 0.5112\n",
      "Epoch 31/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5052\n",
      "Epoch 00031: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 321s 634ms/step - loss: 0.6928 - accuracy: 0.5054 - val_loss: 0.6929 - val_accuracy: 0.5089\n",
      "Epoch 32/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.5093\n",
      "Epoch 00032: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 319s 631ms/step - loss: 0.6944 - accuracy: 0.5090 - val_loss: 0.6930 - val_accuracy: 0.5050\n",
      "Epoch 33/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5033\n",
      "Epoch 00033: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 319s 630ms/step - loss: 0.6933 - accuracy: 0.5032 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 34/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.5185\n",
      "Epoch 00034: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 633ms/step - loss: 0.6922 - accuracy: 0.5186 - val_loss: 0.6927 - val_accuracy: 0.5173\n",
      "Epoch 35/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.5164\n",
      "Epoch 00035: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 321s 635ms/step - loss: 0.6921 - accuracy: 0.5165 - val_loss: 0.6921 - val_accuracy: 0.5033\n",
      "Epoch 36/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.5157\n",
      "Epoch 00036: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 317s 626ms/step - loss: 0.6923 - accuracy: 0.5157 - val_loss: 0.6917 - val_accuracy: 0.5145\n",
      "Epoch 37/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.5224\n",
      "Epoch 00037: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 321s 634ms/step - loss: 0.6921 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5117\n",
      "Epoch 38/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6906 - accuracy: 0.5218\n",
      "Epoch 00038: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 315s 622ms/step - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6915 - val_accuracy: 0.5128\n",
      "Epoch 39/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.5188\n",
      "Epoch 00039: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 316s 624ms/step - loss: 0.6899 - accuracy: 0.5188 - val_loss: 0.6933 - val_accuracy: 0.5179\n",
      "Epoch 40/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6866 - accuracy: 0.5264\n",
      "Epoch 00040: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 317s 627ms/step - loss: 0.6866 - accuracy: 0.5261 - val_loss: 0.6889 - val_accuracy: 0.5123\n",
      "Epoch 41/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6855 - accuracy: 0.5236\n",
      "Epoch 00041: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 318s 628ms/step - loss: 0.6855 - accuracy: 0.5237 - val_loss: 0.6887 - val_accuracy: 0.5156\n",
      "Epoch 42/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6838 - accuracy: 0.5274\n",
      "Epoch 00042: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 633ms/step - loss: 0.6839 - accuracy: 0.5273 - val_loss: 0.6840 - val_accuracy: 0.5190\n",
      "Epoch 43/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6832 - accuracy: 0.5273\n",
      "Epoch 00043: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 320s 632ms/step - loss: 0.6831 - accuracy: 0.5272 - val_loss: 0.6914 - val_accuracy: 0.5128\n",
      "Epoch 44/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6828 - accuracy: 0.5288\n",
      "Epoch 00044: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 321s 635ms/step - loss: 0.6828 - accuracy: 0.5289 - val_loss: 0.6834 - val_accuracy: 0.5195\n",
      "Epoch 45/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.5314\n",
      "Epoch 00045: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 319s 630ms/step - loss: 0.6783 - accuracy: 0.5315 - val_loss: 0.6789 - val_accuracy: 0.5296\n",
      "Epoch 46/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6778 - accuracy: 0.5387\n",
      "Epoch 00046: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 322s 637ms/step - loss: 0.6779 - accuracy: 0.5388 - val_loss: 0.6840 - val_accuracy: 0.5340\n",
      "Epoch 47/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.5413\n",
      "Epoch 00047: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 318s 628ms/step - loss: 0.6774 - accuracy: 0.5411 - val_loss: 0.6807 - val_accuracy: 0.5324\n",
      "Epoch 48/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.5503\n",
      "Epoch 00048: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 321s 634ms/step - loss: 0.6744 - accuracy: 0.5502 - val_loss: 0.6877 - val_accuracy: 0.5279\n",
      "Epoch 49/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6746 - accuracy: 0.5398\n",
      "Epoch 00049: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 322s 636ms/step - loss: 0.6747 - accuracy: 0.5396 - val_loss: 0.6789 - val_accuracy: 0.5324\n",
      "Epoch 50/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5510\n",
      "Epoch 00050: val_loss did not improve from 0.67874\n",
      "506/506 [==============================] - 323s 639ms/step - loss: 0.6722 - accuracy: 0.5509 - val_loss: 0.6802 - val_accuracy: 0.5547\n",
      "Epoch 51/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6843 - accuracy: 0.5431\n",
      "Epoch 00051: val_loss improved from 0.67874 to 0.67152, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 327s 647ms/step - loss: 0.6843 - accuracy: 0.5430 - val_loss: 0.6715 - val_accuracy: 0.5485\n",
      "Epoch 52/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5578\n",
      "Epoch 00052: val_loss did not improve from 0.67152\n",
      "506/506 [==============================] - 318s 629ms/step - loss: 0.6732 - accuracy: 0.5578 - val_loss: 0.7923 - val_accuracy: 0.5497\n",
      "Epoch 53/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5703\n",
      "Epoch 00053: val_loss improved from 0.67152 to 0.66512, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 322s 636ms/step - loss: 0.6717 - accuracy: 0.5705 - val_loss: 0.6651 - val_accuracy: 0.5837\n",
      "Epoch 54/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6622 - accuracy: 0.5857\n",
      "Epoch 00054: val_loss improved from 0.66512 to 0.66485, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 323s 638ms/step - loss: 0.6621 - accuracy: 0.5859 - val_loss: 0.6648 - val_accuracy: 0.5664\n",
      "Epoch 55/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6607 - accuracy: 0.5848\n",
      "Epoch 00055: val_loss did not improve from 0.66485\n",
      "506/506 [==============================] - 322s 636ms/step - loss: 0.6607 - accuracy: 0.5849 - val_loss: 0.6843 - val_accuracy: 0.5430\n",
      "Epoch 56/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6537 - accuracy: 0.5999\n",
      "Epoch 00056: val_loss improved from 0.66485 to 0.65155, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.6537 - accuracy: 0.5997 - val_loss: 0.6516 - val_accuracy: 0.5898\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/506 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.5973\n",
      "Epoch 00057: val_loss improved from 0.65155 to 0.64464, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 308s 608ms/step - loss: 0.6516 - accuracy: 0.5975 - val_loss: 0.6446 - val_accuracy: 0.5943\n",
      "Epoch 58/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6494 - accuracy: 0.5972\n",
      "Epoch 00058: val_loss did not improve from 0.64464\n",
      "506/506 [==============================] - 316s 625ms/step - loss: 0.6493 - accuracy: 0.5974 - val_loss: 0.6454 - val_accuracy: 0.5965\n",
      "Epoch 59/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6444 - accuracy: 0.6028\n",
      "Epoch 00059: val_loss did not improve from 0.64464\n",
      "506/506 [==============================] - 316s 625ms/step - loss: 0.6443 - accuracy: 0.6030 - val_loss: 0.6542 - val_accuracy: 0.5848\n",
      "Epoch 60/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6475 - accuracy: 0.6021\n",
      "Epoch 00060: val_loss did not improve from 0.64464\n",
      "506/506 [==============================] - 311s 615ms/step - loss: 0.6475 - accuracy: 0.6021 - val_loss: 0.6538 - val_accuracy: 0.5949\n",
      "Epoch 61/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6430 - accuracy: 0.6052\n",
      "Epoch 00061: val_loss did not improve from 0.64464\n",
      "506/506 [==============================] - 311s 616ms/step - loss: 0.6429 - accuracy: 0.6053 - val_loss: 0.6498 - val_accuracy: 0.5999\n",
      "Epoch 62/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6438 - accuracy: 0.6027\n",
      "Epoch 00062: val_loss improved from 0.64464 to 0.64068, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 315s 622ms/step - loss: 0.6438 - accuracy: 0.6027 - val_loss: 0.6407 - val_accuracy: 0.6138\n",
      "Epoch 63/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6388 - accuracy: 0.6115\n",
      "Epoch 00063: val_loss improved from 0.64068 to 0.63566, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 309s 610ms/step - loss: 0.6387 - accuracy: 0.6116 - val_loss: 0.6357 - val_accuracy: 0.6211\n",
      "Epoch 64/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6397 - accuracy: 0.6132\n",
      "Epoch 00064: val_loss did not improve from 0.63566\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.6396 - accuracy: 0.6131 - val_loss: 0.6381 - val_accuracy: 0.6088\n",
      "Epoch 65/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6363 - accuracy: 0.6144\n",
      "Epoch 00065: val_loss did not improve from 0.63566\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.6361 - accuracy: 0.6146 - val_loss: 0.6395 - val_accuracy: 0.6055\n",
      "Epoch 66/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6329 - accuracy: 0.6135\n",
      "Epoch 00066: val_loss did not improve from 0.63566\n",
      "506/506 [==============================] - 310s 613ms/step - loss: 0.6331 - accuracy: 0.6131 - val_loss: 0.6492 - val_accuracy: 0.5960\n",
      "Epoch 67/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6343 - accuracy: 0.6147\n",
      "Epoch 00067: val_loss did not improve from 0.63566\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.6343 - accuracy: 0.6149 - val_loss: 0.6535 - val_accuracy: 0.6049\n",
      "Epoch 68/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6301 - accuracy: 0.6207\n",
      "Epoch 00068: val_loss did not improve from 0.63566\n",
      "506/506 [==============================] - 318s 628ms/step - loss: 0.6301 - accuracy: 0.6209 - val_loss: 0.6432 - val_accuracy: 0.6172\n",
      "Epoch 69/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6326 - accuracy: 0.6179\n",
      "Epoch 00069: val_loss improved from 0.63566 to 0.63224, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.6327 - accuracy: 0.6176 - val_loss: 0.6322 - val_accuracy: 0.6172\n",
      "Epoch 70/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6263 - accuracy: 0.6290\n",
      "Epoch 00070: val_loss improved from 0.63224 to 0.62957, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 314s 620ms/step - loss: 0.6262 - accuracy: 0.6292 - val_loss: 0.6296 - val_accuracy: 0.6211\n",
      "Epoch 71/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6267 - accuracy: 0.6241\n",
      "Epoch 00071: val_loss improved from 0.62957 to 0.62589, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 312s 616ms/step - loss: 0.6268 - accuracy: 0.6241 - val_loss: 0.6259 - val_accuracy: 0.6122\n",
      "Epoch 72/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.6212\n",
      "Epoch 00072: val_loss did not improve from 0.62589\n",
      "506/506 [==============================] - 310s 612ms/step - loss: 0.6281 - accuracy: 0.6212 - val_loss: 0.6407 - val_accuracy: 0.6010\n",
      "Epoch 73/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6275 - accuracy: 0.6261\n",
      "Epoch 00073: val_loss did not improve from 0.62589\n",
      "506/506 [==============================] - 312s 616ms/step - loss: 0.6274 - accuracy: 0.6261 - val_loss: 0.6390 - val_accuracy: 0.6038\n",
      "Epoch 74/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.6352\n",
      "Epoch 00074: val_loss did not improve from 0.62589\n",
      "506/506 [==============================] - 310s 613ms/step - loss: 0.6189 - accuracy: 0.6351 - val_loss: 0.6738 - val_accuracy: 0.5759\n",
      "Epoch 75/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6190 - accuracy: 0.6329\n",
      "Epoch 00075: val_loss improved from 0.62589 to 0.61723, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 316s 625ms/step - loss: 0.6189 - accuracy: 0.6329 - val_loss: 0.6172 - val_accuracy: 0.6390\n",
      "Epoch 76/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6175 - accuracy: 0.6350\n",
      "Epoch 00076: val_loss did not improve from 0.61723\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.6174 - accuracy: 0.6350 - val_loss: 0.6254 - val_accuracy: 0.6373\n",
      "Epoch 77/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6141 - accuracy: 0.6413\n",
      "Epoch 00077: val_loss did not improve from 0.61723\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.6141 - accuracy: 0.6412 - val_loss: 0.6180 - val_accuracy: 0.6429\n",
      "Epoch 78/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6145 - accuracy: 0.6422\n",
      "Epoch 00078: val_loss improved from 0.61723 to 0.61270, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.6145 - accuracy: 0.6422 - val_loss: 0.6127 - val_accuracy: 0.6395\n",
      "Epoch 79/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6096 - accuracy: 0.6482\n",
      "Epoch 00079: val_loss did not improve from 0.61270\n",
      "506/506 [==============================] - 309s 612ms/step - loss: 0.6098 - accuracy: 0.6480 - val_loss: 0.6181 - val_accuracy: 0.6417\n",
      "Epoch 80/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6048 - accuracy: 0.6520\n",
      "Epoch 00080: val_loss did not improve from 0.61270\n",
      "506/506 [==============================] - 310s 613ms/step - loss: 0.6049 - accuracy: 0.6520 - val_loss: 0.6212 - val_accuracy: 0.6417\n",
      "Epoch 81/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6013 - accuracy: 0.6534\n",
      "Epoch 00081: val_loss improved from 0.61270 to 0.59298, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 311s 615ms/step - loss: 0.6013 - accuracy: 0.6533 - val_loss: 0.5930 - val_accuracy: 0.6657\n",
      "Epoch 82/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5960 - accuracy: 0.6649\n",
      "Epoch 00082: val_loss did not improve from 0.59298\n",
      "506/506 [==============================] - 310s 613ms/step - loss: 0.5960 - accuracy: 0.6650 - val_loss: 0.6427 - val_accuracy: 0.6328\n",
      "Epoch 83/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5915 - accuracy: 0.6678\n",
      "Epoch 00083: val_loss did not improve from 0.59298\n",
      "506/506 [==============================] - 311s 614ms/step - loss: 0.5915 - accuracy: 0.6677 - val_loss: 0.6112 - val_accuracy: 0.6468\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/506 [============================>.] - ETA: 0s - loss: 0.5917 - accuracy: 0.6655\n",
      "Epoch 00084: val_loss did not improve from 0.59298\n",
      "506/506 [==============================] - 312s 616ms/step - loss: 0.5918 - accuracy: 0.6655 - val_loss: 0.5994 - val_accuracy: 0.6602\n",
      "Epoch 85/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5868 - accuracy: 0.6717\n",
      "Epoch 00085: val_loss did not improve from 0.59298\n",
      "506/506 [==============================] - 311s 615ms/step - loss: 0.5869 - accuracy: 0.6717 - val_loss: 0.6347 - val_accuracy: 0.6406\n",
      "Epoch 86/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5800 - accuracy: 0.6769\n",
      "Epoch 00086: val_loss improved from 0.59298 to 0.59062, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.5798 - accuracy: 0.6771 - val_loss: 0.5906 - val_accuracy: 0.6735\n",
      "Epoch 87/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5808 - accuracy: 0.6797\n",
      "Epoch 00087: val_loss did not improve from 0.59062\n",
      "506/506 [==============================] - 312s 616ms/step - loss: 0.5809 - accuracy: 0.6797 - val_loss: 0.6027 - val_accuracy: 0.6669\n",
      "Epoch 88/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5710 - accuracy: 0.6898\n",
      "Epoch 00088: val_loss did not improve from 0.59062\n",
      "506/506 [==============================] - 313s 618ms/step - loss: 0.5710 - accuracy: 0.6898 - val_loss: 0.5976 - val_accuracy: 0.6629\n",
      "Epoch 89/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.6885\n",
      "Epoch 00089: val_loss did not improve from 0.59062\n",
      "506/506 [==============================] - 309s 611ms/step - loss: 0.5704 - accuracy: 0.6883 - val_loss: 0.5973 - val_accuracy: 0.6618\n",
      "Epoch 90/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5662 - accuracy: 0.6937\n",
      "Epoch 00090: val_loss did not improve from 0.59062\n",
      "506/506 [==============================] - 310s 612ms/step - loss: 0.5665 - accuracy: 0.6936 - val_loss: 0.5942 - val_accuracy: 0.6669\n",
      "Epoch 91/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5630 - accuracy: 0.6964\n",
      "Epoch 00091: val_loss improved from 0.59062 to 0.58608, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 313s 618ms/step - loss: 0.5631 - accuracy: 0.6964 - val_loss: 0.5861 - val_accuracy: 0.6925\n",
      "Epoch 92/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5543 - accuracy: 0.7003\n",
      "Epoch 00092: val_loss did not improve from 0.58608\n",
      "506/506 [==============================] - 310s 614ms/step - loss: 0.5544 - accuracy: 0.7002 - val_loss: 0.5976 - val_accuracy: 0.6735\n",
      "Epoch 93/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5563 - accuracy: 0.7050\n",
      "Epoch 00093: val_loss improved from 0.58608 to 0.58606, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 314s 620ms/step - loss: 0.5563 - accuracy: 0.7048 - val_loss: 0.5861 - val_accuracy: 0.6747\n",
      "Epoch 94/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5464 - accuracy: 0.7081\n",
      "Epoch 00094: val_loss improved from 0.58606 to 0.57731, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.5463 - accuracy: 0.7082 - val_loss: 0.5773 - val_accuracy: 0.6953\n",
      "Epoch 95/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.7105\n",
      "Epoch 00095: val_loss did not improve from 0.57731\n",
      "506/506 [==============================] - 309s 611ms/step - loss: 0.5409 - accuracy: 0.7108 - val_loss: 0.5780 - val_accuracy: 0.6719\n",
      "Epoch 96/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5398 - accuracy: 0.7195\n",
      "Epoch 00096: val_loss improved from 0.57731 to 0.56955, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 315s 622ms/step - loss: 0.5400 - accuracy: 0.7195 - val_loss: 0.5696 - val_accuracy: 0.6886\n",
      "Epoch 97/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.7199\n",
      "Epoch 00097: val_loss did not improve from 0.56955\n",
      "506/506 [==============================] - 311s 614ms/step - loss: 0.5322 - accuracy: 0.7201 - val_loss: 0.6158 - val_accuracy: 0.6825\n",
      "Epoch 98/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5278 - accuracy: 0.7256\n",
      "Epoch 00098: val_loss did not improve from 0.56955\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.5278 - accuracy: 0.7257 - val_loss: 0.6110 - val_accuracy: 0.6808\n",
      "Epoch 99/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5238 - accuracy: 0.7253\n",
      "Epoch 00099: val_loss did not improve from 0.56955\n",
      "506/506 [==============================] - 313s 618ms/step - loss: 0.5240 - accuracy: 0.7253 - val_loss: 0.5968 - val_accuracy: 0.6735\n",
      "Epoch 100/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5180 - accuracy: 0.7369\n",
      "Epoch 00100: val_loss improved from 0.56955 to 0.55650, saving model to checkpoint-TK_diff-smalldata.h5\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.5179 - accuracy: 0.7370 - val_loss: 0.5565 - val_accuracy: 0.7026\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, train_generator, validation_generator, test_generator, tf.keras.optimizers.Adam(lr = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOGQG83odP4U"
   },
   "source": [
    "**Plot Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8202586,
     "status": "ok",
     "timestamp": 1594870080436,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "g2oyNk4PRDmG",
    "outputId": "37e2d458-be48-47de-f275-fe3e0f6901a7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8203098,
     "status": "ok",
     "timestamp": 1594870080952,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "dFJLAzliRFJz",
    "outputId": "bc985298-1c87-45f4-a361-574ed5ba99ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setupmodel()\n",
    "json_filename = \"TK_diff_model.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(json_filename, \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json \n",
    "json_file = open(json_filename, \"r\") \n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close() \n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "loaded_model.load_weights(\"checkpoint-TK_diff-smalldata.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics - F1, Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Evaluate ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41786373 0.58213627]\n",
      " [0.98802307 0.01197693]\n",
      " [0.22547168 0.77452832]\n",
      " ...\n",
      " [0.57173094 0.42826906]\n",
      " [0.1711973  0.8288027 ]\n",
      " [0.45964557 0.54035443]]\n",
      "[1. 0. 0. ... 0. 1. 1.]\n",
      "[1 0 1 ... 0 1 1]\n",
      "[1. 0. 0. ... 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"== Evaluate ==\")\n",
    "\n",
    "output_score = []\n",
    "output_class = []\n",
    "answer_class = []\n",
    "\n",
    "for i in trange(len(test_generator)):\n",
    "    output = loaded_model.predict_on_batch(test_generator[i][0])\n",
    "    output_score.append(output)\n",
    "    answer_class.append(test_generator[i][1])\n",
    "    \n",
    "output_score = np.concatenate(output_score)\n",
    "answer_class = np.concatenate(answer_class)\n",
    "\n",
    "lst = []\n",
    "for i in output_score:\n",
    "    val = i[0]\n",
    "    sublst = [1-val, val]\n",
    "    lst.append(sublst)\n",
    "    \n",
    "output_score = np.array(lst)\n",
    "\n",
    "print(output_score)\n",
    "print(answer_class)\n",
    "\n",
    "output_class = np.argmax(output_score, axis=1)\n",
    "\n",
    "print(output_class)\n",
    "print(answer_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1000.0\n",
      "2000\n",
      "1210\n"
     ]
    }
   ],
   "source": [
    "print(len(answer_class))\n",
    "\n",
    "cnt = np.sum(answer_class)\n",
    "print(cnt)\n",
    "\n",
    "print(len(output_class))\n",
    "cnt2= np.sum(output_class)\n",
    "print(cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.60      0.67      1000\n",
      "         1.0       0.67      0.81      0.74      1000\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.72      0.71      0.70      2000\n",
      "weighted avg       0.72      0.71      0.70      2000\n",
      "\n",
      "[[603 397]\n",
      " [187 813]]\n",
      "AUROC: 0.782390\n",
      "THRESH:  0.6285647153854199\n",
      "test_acc:  0.708\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(answer_class, output_class)\n",
    "report = classification_report(answer_class, output_class)\n",
    "\n",
    "recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "fallout = cm[1][0] / (cm[1][0] + cm[1][1])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(answer_class, output_score[:, 1], pos_label=1.)\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, thresholds)(eer)\n",
    "\n",
    "print(report)\n",
    "print(cm)\n",
    "print(\"AUROC: %f\" %(roc_auc_score(answer_class, output_score[:, 1])))\n",
    "print(\"THRESH: \" , thresh)\n",
    "print('test_acc: ', len(output_class[np.equal(output_class, answer_class)]) / len(output_class))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPykDpKpzBavJLmF/+k9+Cn",
   "collapsed_sections": [],
   "mount_file_id": "1402Yotl5EV6I7ydoZjvC667pxYPhTEnO",
   "name": "tensor_dcmp_baseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
