{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EltwXFS-h0N"
   },
   "source": [
    "# Baseline Code for Deepfake Detection\n",
    "\n",
    "\n",
    "By Dongmin Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vfYll4q9Dqj"
   },
   "source": [
    "## Data Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2574,
     "status": "ok",
     "timestamp": 1594861880337,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "AkbZHQ3w_3TH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "physical_devices = tf.config.experimental.get_visible_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COfNhpEv6u5S"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGR = lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "TOTAL_DATA_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9626,
     "status": "ok",
     "timestamp": 1594861887408,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "TYD8hU74FOKe"
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20, \n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest',\n",
    "    validation_split = VALID_RATIO,\n",
    ")\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **data_gen_args,\n",
    "    preprocessing_function = BGR\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    preprocessing_function = BGR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM DIR\n",
      "REAL:  10000\n",
      "FAKE:  10000\n",
      "TOTAL:  20000\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "#path = \"/media/data1/hsm/FACE_FORENSICS_C40/DATA_FRAMES/\"\n",
    "path = \"./OR\"\n",
    "real_data_dir = os.path.join(path, 'REAL')\n",
    "fake_data_dir = os.path.join(path, 'FAKE', 'NeuralTextures')\n",
    "\n",
    "real_filenames = np.array([os.path.join('REAL', f) for f in os.listdir(real_data_dir)])\n",
    "fake_filenames = np.array([os.path.join('FAKE', 'NeuralTextures', f) for f in os.listdir(fake_data_dir)])\n",
    "\n",
    "print(\"FROM DIR\")\n",
    "print(\"REAL: \", len(real_filenames))\n",
    "print(\"FAKE: \", len(fake_filenames))\n",
    "print(\"TOTAL: \", len(real_filenames) + len(fake_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling\n",
    "real_filenames = np.random.choice(real_filenames, TOTAL_DATA_SIZE//2, replace = False).tolist()\n",
    "fake_filenames = np.random.choice(fake_filenames, TOTAL_DATA_SIZE//2, replace = False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIM SIZE\n",
      "REAL:  10000\n",
      "FAKE:  10000\n",
      "TOTAL:  20000\n",
      "TRAIN:  16200 VALIDATION:  1800 TEST:  2000\n"
     ]
    }
   ],
   "source": [
    "print(\"TRIM SIZE\")\n",
    "print(\"REAL: \", len(real_filenames))\n",
    "print(\"FAKE: \", len(fake_filenames))\n",
    "print(\"TOTAL: \", len(real_filenames) + len(fake_filenames))\n",
    "\n",
    "total_length = len(real_filenames) + len(fake_filenames)\n",
    "\n",
    "test_length = int(total_length * TEST_RATIO)\n",
    "validation_length = int((total_length-test_length) * VALID_RATIO)\n",
    "train_length = total_length - validation_length - test_length\n",
    "\n",
    "print(\"TRAIN: \", train_length, \"VALIDATION: \", validation_length, \"TEST: \", test_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_filenames_test = real_filenames[:test_length//2]\n",
    "fake_filenames_test = fake_filenames[:test_length//2]\n",
    "real_filenames = real_filenames[test_length//2:]\n",
    "fake_filenames = fake_filenames[test_length//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_categories_test = []\n",
    "for filename in real_filenames_test:\n",
    "    real_categories_test.append('0')\n",
    "        \n",
    "real_testdata = pd.DataFrame({'filename' : real_filenames_test, 'label' : real_categories_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_categories_test = []\n",
    "for filename in fake_filenames_test:\n",
    "    fake_categories_test.append('1')\n",
    "\n",
    "fake_testdata = pd.DataFrame({'filename' : fake_filenames_test, 'label' : fake_categories_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([real_testdata, fake_testdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real : 0, fake : 1\n",
    "categories = []\n",
    "for filename in real_filenames:\n",
    "    categories.append('0')\n",
    "    \n",
    "for filename in fake_filenames:\n",
    "    categories.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'filename' : real_filenames + fake_filenames, 'label' : categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/16__podium_speech_happy_frame1145.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/11__talking_against_wall_frame30.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/133_frame456.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/05__talking_against_wall_frame300.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/672_frame354.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>FAKE/NeuralTextures/211_177_frame120.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>FAKE/NeuralTextures/727_729_frame370.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>FAKE/NeuralTextures/314_347_frame318.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>FAKE/NeuralTextures/546_621_frame210.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>FAKE/NeuralTextures/743_750_frame144.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename label\n",
       "0      REAL/16__podium_speech_happy_frame1145.jpg     0\n",
       "1       REAL/11__talking_against_wall_frame30.jpg     0\n",
       "2                           REAL/133_frame456.jpg     0\n",
       "3      REAL/05__talking_against_wall_frame300.jpg     0\n",
       "4                           REAL/672_frame354.jpg     0\n",
       "...                                           ...   ...\n",
       "17995    FAKE/NeuralTextures/211_177_frame120.jpg     1\n",
       "17996    FAKE/NeuralTextures/727_729_frame370.jpg     1\n",
       "17997    FAKE/NeuralTextures/314_347_frame318.jpg     1\n",
       "17998    FAKE/NeuralTextures/546_621_frame210.jpg     1\n",
       "17999    FAKE/NeuralTextures/743_750_frame144.jpg     1\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[np.random.RandomState(seed = 42).permutation(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>REAL/794_frame430.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>REAL/540_frame170.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>FAKE/NeuralTextures/104_126_frame78.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>REAL/01__kitchen_still_frame250.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>REAL/241_frame210.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>FAKE/NeuralTextures/234_187_frame102.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>FAKE/NeuralTextures/118_120_frame125.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>REAL/744_frame84.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>REAL/074_frame35.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>FAKE/NeuralTextures/544_532_frame270.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename label\n",
       "2574                      REAL/794_frame430.jpg     0\n",
       "7496                      REAL/540_frame170.jpg     0\n",
       "9210    FAKE/NeuralTextures/104_126_frame78.jpg     1\n",
       "5456        REAL/01__kitchen_still_frame250.jpg     0\n",
       "736                       REAL/241_frame210.jpg     0\n",
       "...                                         ...   ...\n",
       "11284  FAKE/NeuralTextures/234_187_frame102.jpg     1\n",
       "11964  FAKE/NeuralTextures/118_120_frame125.jpg     1\n",
       "5390                       REAL/744_frame84.jpg     0\n",
       "860                        REAL/074_frame35.jpg     0\n",
       "15795  FAKE/NeuralTextures/544_532_frame270.jpg     1\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/07__talking_angry_couch_frame1500.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/385_frame72.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/06__walk_down_hall_angry_frame20.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/825_frame420.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/994_frame25.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>FAKE/NeuralTextures/949_868_frame72.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>FAKE/NeuralTextures/579_701_frame96.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>FAKE/NeuralTextures/271_264_frame90.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>FAKE/NeuralTextures/712_716_frame340.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>FAKE/NeuralTextures/359_317_frame294.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename label\n",
       "0    REAL/07__talking_angry_couch_frame1500.jpg     0\n",
       "1                          REAL/385_frame72.jpg     0\n",
       "2     REAL/06__walk_down_hall_angry_frame20.jpg     0\n",
       "3                         REAL/825_frame420.jpg     0\n",
       "4                          REAL/994_frame25.jpg     0\n",
       "..                                          ...   ...\n",
       "995     FAKE/NeuralTextures/949_868_frame72.jpg     1\n",
       "996     FAKE/NeuralTextures/579_701_frame96.jpg     1\n",
       "997     FAKE/NeuralTextures/271_264_frame90.jpg     1\n",
       "998    FAKE/NeuralTextures/712_716_frame340.jpg     1\n",
       "999    FAKE/NeuralTextures/359_317_frame294.jpg     1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1000\n",
       "1    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.groupby(['label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44421,
     "status": "ok",
     "timestamp": 1594861922212,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "JfDhCEOCHMP9",
    "outputId": "bf643961-e321-433e-84f8-7f793bd2efda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16200 validated image filenames belonging to 2 classes.\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "Found 2000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True,\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True,\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53852,
     "status": "ok",
     "timestamp": 1594861931663,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "Q7lrrsvnh0FO",
    "outputId": "763103a8-abec-4e65-91c0-fe6e1a91cf63"
   },
   "outputs": [],
   "source": [
    "# import available models for training\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Dropout\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53849,
     "status": "ok",
     "timestamp": 1594861931664,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "h_qQl7mYM_4H"
   },
   "outputs": [],
   "source": [
    "def setupmodel():\n",
    "    input_tensor = Input(shape = (256,256,3))\n",
    "\n",
    "    base_model = Xception(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_tensor = input_tensor\n",
    "    )\n",
    "    # Setup\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation = \"relu\")(x)\n",
    "    prediction = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # model return\n",
    "    model = Model(base_model.input, prediction)\n",
    "\n",
    "    # trainable\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57132,
     "status": "ok",
     "timestamp": 1594861934952,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "W72UW_JAOqIL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dongmin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = setupmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57125,
     "status": "ok",
     "timestamp": 1594861934955,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "w1aKA6TGPYQJ",
    "outputId": "d713b6a3-c474-4ff3-db93-246221cd12ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 63, 63, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 63, 63, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 63, 63, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 131072)       0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          33554688    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 54,416,425\n",
      "Trainable params: 54,361,897\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57122,
     "status": "ok",
     "timestamp": 1594861934956,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "g2uCmYuC_QFB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(tf.keras.callbacks.Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57119,
     "status": "ok",
     "timestamp": 1594861934957,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "Gg-pDKlNjjf1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, validation_generator, test_generator, optimizer):\n",
    "    # checkpointing\n",
    "    filename = 'checkpoint-baseline-smalldata.h5'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                        filename, \n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,           \n",
    "                        save_best_only=True,\n",
    "                        mode='auto'\n",
    "                )\n",
    "    # early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # Cyclic Learning Rate\n",
    "    clr = CyclicLR(\n",
    "        base_lr=1e-3,#0.001, \n",
    "        max_lr=7e-3,#0.007,\n",
    "        step_size=300., \n",
    "        mode='exp_range',\n",
    "        gamma=0.99994\n",
    "    )\n",
    "    \n",
    "    # compile\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    # train\n",
    "    print(\"== Start Training ==\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = train_length // BATCH_SIZE, \n",
    "        epochs = EPOCHS,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = validation_length // BATCH_SIZE,\n",
    "        callbacks=[checkpoint, clr],\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8202582,
     "status": "ok",
     "timestamp": 1594870080429,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "JzhaoVTjPPw-",
    "outputId": "44580b4c-b6d8-45bb-c65e-ecf7a1ae9c12",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Start Training ==\n",
      "Epoch 1/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.7198 - accuracy: 0.6073\n",
      "Epoch 00001: val_loss improved from inf to 0.63866, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 357s 705ms/step - loss: 0.7194 - accuracy: 0.6075 - val_loss: 0.6387 - val_accuracy: 0.6607\n",
      "Epoch 2/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5845 - accuracy: 0.6984\n",
      "Epoch 00002: val_loss did not improve from 0.63866\n",
      "506/506 [==============================] - 303s 599ms/step - loss: 0.5846 - accuracy: 0.6984 - val_loss: 5.3425 - val_accuracy: 0.5022\n",
      "Epoch 3/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5570 - accuracy: 0.7166\n",
      "Epoch 00003: val_loss did not improve from 0.63866\n",
      "506/506 [==============================] - 299s 592ms/step - loss: 0.5570 - accuracy: 0.7167 - val_loss: 1.4799 - val_accuracy: 0.5290\n",
      "Epoch 4/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.7315\n",
      "Epoch 00004: val_loss did not improve from 0.63866\n",
      "506/506 [==============================] - 301s 594ms/step - loss: 0.5346 - accuracy: 0.7313 - val_loss: 1.6527 - val_accuracy: 0.5681\n",
      "Epoch 5/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.7388\n",
      "Epoch 00005: val_loss improved from 0.63866 to 0.52479, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 299s 591ms/step - loss: 0.5238 - accuracy: 0.7387 - val_loss: 0.5248 - val_accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.7413\n",
      "Epoch 00006: val_loss did not improve from 0.52479\n",
      "506/506 [==============================] - 302s 597ms/step - loss: 0.5175 - accuracy: 0.7413 - val_loss: 0.6437 - val_accuracy: 0.6981\n",
      "Epoch 7/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5040 - accuracy: 0.7502\n",
      "Epoch 00007: val_loss did not improve from 0.52479\n",
      "506/506 [==============================] - 299s 590ms/step - loss: 0.5041 - accuracy: 0.7501 - val_loss: 0.6362 - val_accuracy: 0.7204\n",
      "Epoch 8/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.7593\n",
      "Epoch 00008: val_loss did not improve from 0.52479\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.4866 - accuracy: 0.7594 - val_loss: 0.7160 - val_accuracy: 0.7271\n",
      "Epoch 9/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.7699\n",
      "Epoch 00009: val_loss did not improve from 0.52479\n",
      "506/506 [==============================] - 292s 578ms/step - loss: 0.4690 - accuracy: 0.7699 - val_loss: 0.7278 - val_accuracy: 0.7221\n",
      "Epoch 10/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.7763\n",
      "Epoch 00010: val_loss did not improve from 0.52479\n",
      "506/506 [==============================] - 291s 576ms/step - loss: 0.4606 - accuracy: 0.7762 - val_loss: 0.6379 - val_accuracy: 0.6551\n",
      "Epoch 11/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4603 - accuracy: 0.7745\n",
      "Epoch 00011: val_loss improved from 0.52479 to 0.48100, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 293s 580ms/step - loss: 0.4606 - accuracy: 0.7742 - val_loss: 0.4810 - val_accuracy: 0.7746\n",
      "Epoch 12/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4537 - accuracy: 0.7744\n",
      "Epoch 00012: val_loss did not improve from 0.48100\n",
      "506/506 [==============================] - 290s 574ms/step - loss: 0.4534 - accuracy: 0.7746 - val_loss: 0.4934 - val_accuracy: 0.7612\n",
      "Epoch 13/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4505 - accuracy: 0.7848\n",
      "Epoch 00013: val_loss improved from 0.48100 to 0.45936, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 293s 580ms/step - loss: 0.4503 - accuracy: 0.7849 - val_loss: 0.4594 - val_accuracy: 0.7846\n",
      "Epoch 14/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4336 - accuracy: 0.7917\n",
      "Epoch 00014: val_loss did not improve from 0.45936\n",
      "506/506 [==============================] - 299s 591ms/step - loss: 0.4337 - accuracy: 0.7917 - val_loss: 0.6807 - val_accuracy: 0.6579\n",
      "Epoch 15/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8014\n",
      "Epoch 00015: val_loss did not improve from 0.45936\n",
      "506/506 [==============================] - 305s 603ms/step - loss: 0.4171 - accuracy: 0.8015 - val_loss: 0.5269 - val_accuracy: 0.7461\n",
      "Epoch 16/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3971 - accuracy: 0.8154\n",
      "Epoch 00016: val_loss did not improve from 0.45936\n",
      "506/506 [==============================] - 298s 588ms/step - loss: 0.3968 - accuracy: 0.8156 - val_loss: 0.5145 - val_accuracy: 0.7628\n",
      "Epoch 17/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3986 - accuracy: 0.8139\n",
      "Epoch 00017: val_loss did not improve from 0.45936\n",
      "506/506 [==============================] - 295s 584ms/step - loss: 0.3985 - accuracy: 0.8139 - val_loss: 0.5048 - val_accuracy: 0.7511\n",
      "Epoch 18/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8208\n",
      "Epoch 00018: val_loss improved from 0.45936 to 0.45334, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 300s 593ms/step - loss: 0.3872 - accuracy: 0.8211 - val_loss: 0.4533 - val_accuracy: 0.7952\n",
      "Epoch 19/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8219\n",
      "Epoch 00019: val_loss did not improve from 0.45334\n",
      "506/506 [==============================] - 297s 587ms/step - loss: 0.3813 - accuracy: 0.8219 - val_loss: 0.4536 - val_accuracy: 0.7958\n",
      "Epoch 20/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3720 - accuracy: 0.8323\n",
      "Epoch 00020: val_loss improved from 0.45334 to 0.43321, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 300s 593ms/step - loss: 0.3719 - accuracy: 0.8324 - val_loss: 0.4332 - val_accuracy: 0.8136\n",
      "Epoch 21/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.8395\n",
      "Epoch 00021: val_loss did not improve from 0.43321\n",
      "506/506 [==============================] - 295s 584ms/step - loss: 0.3587 - accuracy: 0.8393 - val_loss: 0.5958 - val_accuracy: 0.7232\n",
      "Epoch 22/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3401 - accuracy: 0.8449\n",
      "Epoch 00022: val_loss did not improve from 0.43321\n",
      "506/506 [==============================] - 297s 587ms/step - loss: 0.3400 - accuracy: 0.8449 - val_loss: 0.4745 - val_accuracy: 0.7785\n",
      "Epoch 23/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8595\n",
      "Epoch 00023: val_loss did not improve from 0.43321\n",
      "506/506 [==============================] - 296s 586ms/step - loss: 0.3218 - accuracy: 0.8595 - val_loss: 1.3121 - val_accuracy: 0.6334\n",
      "Epoch 24/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.8567\n",
      "Epoch 00024: val_loss improved from 0.43321 to 0.40472, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 297s 587ms/step - loss: 0.3214 - accuracy: 0.8569 - val_loss: 0.4047 - val_accuracy: 0.8175\n",
      "Epoch 25/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3198 - accuracy: 0.8620\n",
      "Epoch 00025: val_loss improved from 0.40472 to 0.36043, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 298s 589ms/step - loss: 0.3199 - accuracy: 0.8619 - val_loss: 0.3604 - val_accuracy: 0.8281\n",
      "Epoch 26/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.8620\n",
      "Epoch 00026: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 296s 586ms/step - loss: 0.3117 - accuracy: 0.8621 - val_loss: 0.3774 - val_accuracy: 0.8326\n",
      "Epoch 27/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.8738\n",
      "Epoch 00027: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 295s 583ms/step - loss: 0.2931 - accuracy: 0.8735 - val_loss: 0.3723 - val_accuracy: 0.8331\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/506 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.8826\n",
      "Epoch 00028: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 295s 583ms/step - loss: 0.2721 - accuracy: 0.8828 - val_loss: 0.4310 - val_accuracy: 0.8025\n",
      "Epoch 29/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2678 - accuracy: 0.8834\n",
      "Epoch 00029: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 297s 586ms/step - loss: 0.2678 - accuracy: 0.8833 - val_loss: 0.4277 - val_accuracy: 0.8041\n",
      "Epoch 30/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.8891\n",
      "Epoch 00030: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.2616 - accuracy: 0.8892 - val_loss: 0.4902 - val_accuracy: 0.8103\n",
      "Epoch 31/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.8915\n",
      "Epoch 00031: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.2562 - accuracy: 0.8913 - val_loss: 0.3838 - val_accuracy: 0.8371\n",
      "Epoch 32/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.8981\n",
      "Epoch 00032: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.2447 - accuracy: 0.8980 - val_loss: 0.3627 - val_accuracy: 0.8532\n",
      "Epoch 33/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2409 - accuracy: 0.9005\n",
      "Epoch 00033: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 295s 583ms/step - loss: 0.2407 - accuracy: 0.9006 - val_loss: 0.4697 - val_accuracy: 0.8410\n",
      "Epoch 34/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9110\n",
      "Epoch 00034: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 293s 580ms/step - loss: 0.2163 - accuracy: 0.9111 - val_loss: 0.4234 - val_accuracy: 0.8421\n",
      "Epoch 35/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9181\n",
      "Epoch 00035: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.2091 - accuracy: 0.9179 - val_loss: 0.4801 - val_accuracy: 0.8086\n",
      "Epoch 36/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.9155\n",
      "Epoch 00036: val_loss did not improve from 0.36043\n",
      "506/506 [==============================] - 292s 578ms/step - loss: 0.2073 - accuracy: 0.9156 - val_loss: 0.3862 - val_accuracy: 0.8398\n",
      "Epoch 37/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2020 - accuracy: 0.9190\n",
      "Epoch 00037: val_loss improved from 0.36043 to 0.34010, saving model to checkpoint-baseline-smalldata.h5\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.2019 - accuracy: 0.9191 - val_loss: 0.3401 - val_accuracy: 0.8566\n",
      "Epoch 38/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9219\n",
      "Epoch 00038: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 583ms/step - loss: 0.1948 - accuracy: 0.9216 - val_loss: 1.3847 - val_accuracy: 0.7232\n",
      "Epoch 39/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1880 - accuracy: 0.9238\n",
      "Epoch 00039: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 584ms/step - loss: 0.1879 - accuracy: 0.9239 - val_loss: 0.3826 - val_accuracy: 0.8482\n",
      "Epoch 40/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 0.9292\n",
      "Epoch 00040: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.1766 - accuracy: 0.9291 - val_loss: 0.5036 - val_accuracy: 0.8175\n",
      "Epoch 41/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1654 - accuracy: 0.9341\n",
      "Epoch 00041: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.1653 - accuracy: 0.9342 - val_loss: 0.6066 - val_accuracy: 0.7930\n",
      "Epoch 42/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9357\n",
      "Epoch 00042: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 578ms/step - loss: 0.1593 - accuracy: 0.9357 - val_loss: 0.3606 - val_accuracy: 0.8588\n",
      "Epoch 43/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.9388\n",
      "Epoch 00043: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.1570 - accuracy: 0.9389 - val_loss: 0.3796 - val_accuracy: 0.8549\n",
      "Epoch 44/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9416\n",
      "Epoch 00044: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.1494 - accuracy: 0.9416 - val_loss: 0.3840 - val_accuracy: 0.8655\n",
      "Epoch 45/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9407\n",
      "Epoch 00045: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 296s 584ms/step - loss: 0.1502 - accuracy: 0.9407 - val_loss: 0.3422 - val_accuracy: 0.8672\n",
      "Epoch 46/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9453\n",
      "Epoch 00046: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.1405 - accuracy: 0.9452 - val_loss: 0.3942 - val_accuracy: 0.8616\n",
      "Epoch 47/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9455\n",
      "Epoch 00047: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.1332 - accuracy: 0.9455 - val_loss: 0.3910 - val_accuracy: 0.8622\n",
      "Epoch 48/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9520\n",
      "Epoch 00048: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 292s 577ms/step - loss: 0.1179 - accuracy: 0.9521 - val_loss: 0.5071 - val_accuracy: 0.8265\n",
      "Epoch 49/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1244 - accuracy: 0.9523\n",
      "Epoch 00049: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.1242 - accuracy: 0.9524 - val_loss: 0.3594 - val_accuracy: 0.8789\n",
      "Epoch 50/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.9552\n",
      "Epoch 00050: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.1153 - accuracy: 0.9552 - val_loss: 0.3674 - val_accuracy: 0.8622\n",
      "Epoch 51/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9577\n",
      "Epoch 00051: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.1109 - accuracy: 0.9577 - val_loss: 0.5457 - val_accuracy: 0.8488\n",
      "Epoch 52/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.9538\n",
      "Epoch 00052: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.1130 - accuracy: 0.9538 - val_loss: 0.4388 - val_accuracy: 0.8689\n",
      "Epoch 53/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.9614\n",
      "Epoch 00053: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.1033 - accuracy: 0.9613 - val_loss: 0.6130 - val_accuracy: 0.8337\n",
      "Epoch 54/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9608\n",
      "Epoch 00054: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.0967 - accuracy: 0.9608 - val_loss: 0.3757 - val_accuracy: 0.8627\n",
      "Epoch 55/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9651\n",
      "Epoch 00055: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 580ms/step - loss: 0.0918 - accuracy: 0.9652 - val_loss: 0.4993 - val_accuracy: 0.8583\n",
      "Epoch 56/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 0.9668\n",
      "Epoch 00056: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.0889 - accuracy: 0.9669 - val_loss: 0.4403 - val_accuracy: 0.8722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9641\n",
      "Epoch 00057: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 580ms/step - loss: 0.0927 - accuracy: 0.9641 - val_loss: 0.4027 - val_accuracy: 0.8817\n",
      "Epoch 58/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9663\n",
      "Epoch 00058: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.0870 - accuracy: 0.9663 - val_loss: 0.3947 - val_accuracy: 0.8783\n",
      "Epoch 59/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9694\n",
      "Epoch 00059: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0813 - accuracy: 0.9692 - val_loss: 0.4158 - val_accuracy: 0.8811\n",
      "Epoch 60/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9694\n",
      "Epoch 00060: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 578ms/step - loss: 0.0778 - accuracy: 0.9694 - val_loss: 0.4835 - val_accuracy: 0.8281\n",
      "Epoch 61/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9728\n",
      "Epoch 00061: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 296s 584ms/step - loss: 0.0745 - accuracy: 0.9728 - val_loss: 0.5106 - val_accuracy: 0.8432\n",
      "Epoch 62/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9719\n",
      "Epoch 00062: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 580ms/step - loss: 0.0777 - accuracy: 0.9719 - val_loss: 0.5175 - val_accuracy: 0.8666\n",
      "Epoch 63/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9719\n",
      "Epoch 00063: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.0757 - accuracy: 0.9718 - val_loss: 0.3847 - val_accuracy: 0.8850\n",
      "Epoch 64/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9733\n",
      "Epoch 00064: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0711 - accuracy: 0.9734 - val_loss: 0.4218 - val_accuracy: 0.8756\n",
      "Epoch 65/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9764\n",
      "Epoch 00065: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.0643 - accuracy: 0.9764 - val_loss: 0.4202 - val_accuracy: 0.8677\n",
      "Epoch 66/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9770\n",
      "Epoch 00066: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.0599 - accuracy: 0.9770 - val_loss: 0.5374 - val_accuracy: 0.8633\n",
      "Epoch 67/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9778\n",
      "Epoch 00067: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.0624 - accuracy: 0.9779 - val_loss: 0.4818 - val_accuracy: 0.8443\n",
      "Epoch 68/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9775\n",
      "Epoch 00068: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 580ms/step - loss: 0.0612 - accuracy: 0.9775 - val_loss: 0.4460 - val_accuracy: 0.8633\n",
      "Epoch 69/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9747\n",
      "Epoch 00069: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 578ms/step - loss: 0.0708 - accuracy: 0.9747 - val_loss: 0.4417 - val_accuracy: 0.8650\n",
      "Epoch 70/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9773\n",
      "Epoch 00070: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 292s 578ms/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 0.5439 - val_accuracy: 0.8594\n",
      "Epoch 71/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9781\n",
      "Epoch 00071: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 296s 584ms/step - loss: 0.0609 - accuracy: 0.9781 - val_loss: 0.3879 - val_accuracy: 0.8795\n",
      "Epoch 72/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9804\n",
      "Epoch 00072: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 292s 578ms/step - loss: 0.0522 - accuracy: 0.9803 - val_loss: 0.4694 - val_accuracy: 0.8549\n",
      "Epoch 73/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9771\n",
      "Epoch 00073: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.0614 - accuracy: 0.9771 - val_loss: 0.4677 - val_accuracy: 0.8750\n",
      "Epoch 74/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9830\n",
      "Epoch 00074: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0464 - accuracy: 0.9828 - val_loss: 0.4991 - val_accuracy: 0.8828\n",
      "Epoch 75/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9810\n",
      "Epoch 00075: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 578ms/step - loss: 0.0524 - accuracy: 0.9809 - val_loss: 0.6526 - val_accuracy: 0.8616\n",
      "Epoch 76/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9802\n",
      "Epoch 00076: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 579ms/step - loss: 0.0530 - accuracy: 0.9803 - val_loss: 0.4119 - val_accuracy: 0.8923\n",
      "Epoch 77/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9805\n",
      "Epoch 00077: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0495 - accuracy: 0.9804 - val_loss: 0.4364 - val_accuracy: 0.8850\n",
      "Epoch 78/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9848\n",
      "Epoch 00078: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 584ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.4672 - val_accuracy: 0.8839\n",
      "Epoch 79/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9824\n",
      "Epoch 00079: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 578ms/step - loss: 0.0472 - accuracy: 0.9824 - val_loss: 0.6712 - val_accuracy: 0.8477\n",
      "Epoch 80/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9832\n",
      "Epoch 00080: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 578ms/step - loss: 0.0463 - accuracy: 0.9832 - val_loss: 0.5277 - val_accuracy: 0.8666\n",
      "Epoch 81/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9820\n",
      "Epoch 00081: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 583ms/step - loss: 0.0486 - accuracy: 0.9821 - val_loss: 0.4395 - val_accuracy: 0.8806\n",
      "Epoch 82/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9851\n",
      "Epoch 00082: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 292s 578ms/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 0.5140 - val_accuracy: 0.8945\n",
      "Epoch 83/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9836\n",
      "Epoch 00083: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 583ms/step - loss: 0.0437 - accuracy: 0.9836 - val_loss: 0.4772 - val_accuracy: 0.8867\n",
      "Epoch 84/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9844\n",
      "Epoch 00084: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.5163 - val_accuracy: 0.8795\n",
      "Epoch 85/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9817\n",
      "Epoch 00085: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 582ms/step - loss: 0.0471 - accuracy: 0.9816 - val_loss: 0.7250 - val_accuracy: 0.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9852\n",
      "Epoch 00086: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 293s 578ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.4599 - val_accuracy: 0.8811\n",
      "Epoch 87/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9864\n",
      "Epoch 00087: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 296s 585ms/step - loss: 0.0382 - accuracy: 0.9863 - val_loss: 0.5004 - val_accuracy: 0.8683\n",
      "Epoch 88/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9868\n",
      "Epoch 00088: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.4866 - val_accuracy: 0.8700\n",
      "Epoch 89/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9848\n",
      "Epoch 00089: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 0.4580 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9848\n",
      "Epoch 00090: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.0428 - accuracy: 0.9848 - val_loss: 0.4325 - val_accuracy: 0.8895\n",
      "Epoch 91/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9868\n",
      "Epoch 00091: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 584ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.4220 - val_accuracy: 0.8884\n",
      "Epoch 92/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9889\n",
      "Epoch 00092: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 292s 576ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.5370 - val_accuracy: 0.8644\n",
      "Epoch 93/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9867\n",
      "Epoch 00093: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.4059 - val_accuracy: 0.8906\n",
      "Epoch 94/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9851\n",
      "Epoch 00094: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.5358 - val_accuracy: 0.8499\n",
      "Epoch 95/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9891\n",
      "Epoch 00095: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.0312 - accuracy: 0.9891 - val_loss: 0.4840 - val_accuracy: 0.8795\n",
      "Epoch 96/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9877\n",
      "Epoch 00096: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 581ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 0.4564 - val_accuracy: 0.8839\n",
      "Epoch 97/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9872\n",
      "Epoch 00097: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 294s 582ms/step - loss: 0.0366 - accuracy: 0.9871 - val_loss: 0.4869 - val_accuracy: 0.8756\n",
      "Epoch 98/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9892\n",
      "Epoch 00098: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 295s 583ms/step - loss: 0.0308 - accuracy: 0.9892 - val_loss: 0.8760 - val_accuracy: 0.8488\n",
      "Epoch 99/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9880\n",
      "Epoch 00099: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 298s 588ms/step - loss: 0.0348 - accuracy: 0.9880 - val_loss: 0.4593 - val_accuracy: 0.8923\n",
      "Epoch 100/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9876\n",
      "Epoch 00100: val_loss did not improve from 0.34010\n",
      "506/506 [==============================] - 296s 584ms/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.6056 - val_accuracy: 0.8923\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, train_generator, validation_generator, test_generator, tf.keras.optimizers.Adam(lr = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOGQG83odP4U"
   },
   "source": [
    "**Plot Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8202586,
     "status": "ok",
     "timestamp": 1594870080436,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "g2oyNk4PRDmG",
    "outputId": "37e2d458-be48-47de-f275-fe3e0f6901a7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3zU9f34n+/sHTIhJEAChCnICDhABEQF96oFJ7bKr1qLq0Pbfuvosq211lZt3VZx4F6IiqKIyAp7yiYhQBbZ45Lc+/fH+y53SS7JJbnLkdzr+XjkcfeZ9/7cwfv1fm2ltUYQBEHwXwJ8PQBBEATBt4ggEARB8HNEEAiCIPg5IggEQRD8HBEEgiAIfk6QrwfQURITE3V6erqvhyEIgtCjyM7OLtRaJ7k61uMEQXp6OuvXr/f1MARBEHoUSqlDrR0T05AgCIKf4zVBoJR6XimVr5Ta1spxpZR6XCm1Vym1RSk1wVtjEQRBEFrHmxrBi8DsNo7PATJtfwuAp7w4FkEQBKEVvOYj0FqvUEqlt3HKpcD/tKlxsVop1UcplaK1PtrRz6qrqyM3N5eamppOjlZwJiwsjLS0NIKDg309FEEQugFfOotTgRyn7VzbvhaCQCm1AKM1MHDgwBY3ys3NJTo6mvT0dJRS3hmtn6C1pqioiNzcXDIyMnw9HEEQugFfOotdzdguK+BprZ/WWmdprbOSklpGP9XU1JCQkCBCwAMopUhISBDtShD8CF8KglxggNN2GpDX2ZuJEPAc8l0Kgn/hS9PQB8DtSqnXgdOA0s74BwRBEHxJfYOVzbkl1DVoJgyMIyTI9fr6YGElaw8Uk5EUybDkaGIjmvrgausbyD54gk25JfSPDWdochRDkqIIDwn0+jN4TRAopV4DpgOJSqlc4H4gGEBr/R9gCXABsBeoAm7y1li8TUlJCa+++iq33XZbh6674IILePXVV+nTp0+r5/zud79j2rRpzJo1q6vDFATBBZZ6K0dKqjlUVElRhYUTVRZKq+vISIxkamYiydFhTc7XWrOvoJLv9hexck8Bq/YWUV5bD0BUaBBnZSYyNTORsal9GNYvioLyWv71xV7e2pBLg9Vh/U6MCiUxKoSEqBAClGL9wRNU1zW0GF9kSCCx4cHEhAfzs5mZXDg2xePfgeppjWmysrJ088zinTt3MnLkSB+NCA4ePMhFF13Etm1NUyYaGhoIDPS+NPcGvv5OBf+msrae51YeoKiilnNH9eO0wfEEB5qVttWqadC6cRtgb345r67JYVPOCTKTozklNYb0xEiKKiwcKammvKaemSOSmZQeh1KKaksDr687zCurD3GgsBJrG9PgyJQY+seG0aA1DVbN7mPl5JfXApDaJ5xpwxI5KzOJwADFV7vz+XJXPsfLzPGgAGNmDVCKa04byNzJAzhaWsP3x8o5UFhJYYWF4spaauqsZKXHcVZmEpPS4ygor2VPfgX7CyoorqyjrKaO0uo6rjt9EGcPc1klol2UUtla6yyXx0QQdJ25c+fy/vvvM3z4cIKDg4mKiiIlJYVNmzaxY8cOLrvsMnJycqipqeGOO+5gwYIFgKNcRkVFBXPmzGHq1KmsWrWK1NRU3n//fcLDw5k/fz4XXXQRV111Fenp6dx44418+OGH1NXV8eabbzJixAgKCgq45pprKCoqYtKkSSxdupTs7GwSExM7/Uy+/k6F3sW2I6Xc/8F2woMDOS0jnskZ8QxJjiIuIoTAAIdPymrVvL/5CA9/sovjZbWEBgVQW28lNjyYIUmRHC+rJb+8hgarJi0ugozESCpr61l/6ATBgYqxaX3YX1DBiaq6Jp8fGKBosGoGJUQwdWgin2w7RnGlhaxBcZw5JIGBCZEMSoggOTqUPhEhRIUGsfNoGSv2FPDt3kJKq+sIUIoApRgQH8GZQxLMdfERLXxqWmtyiqvZllfKtiOlNFg1N56ZTv8+4d3yXbdGW4Kgx9Uaao8HP9zOjrwyj95zVP8Y7r94dKvHH374YbZt28amTZv46quvuPDCC9m2bVtj+OXzzz9PfHw81dXVTJo0iSuvvJKEhIQm99izZw+vvfYazzzzDFdffTVvv/021113XYvPSkxMZMOGDTz55JM88sgjPPvsszz44IPMnDmT++67j6VLl/L000979PkFoT0qautZuaeQ5bvy2ZhzgqlDk5h/ZjoD4sN5de1hHvxwB3ERwcRFhPD3z79vvC5AQXxkKKFBAdRbrdTUWSmtrmNsWixPXjuBUSmxfLOngKXbj3G0pIbJGfH0jQkjKEBxsKiSA4WVNFg1984ZwVUT00iMCkVrTV5pDYeLqkiKDqV/H2Pa+WTrMd7KzuXVtYeZMTyZ26YPISs9vtVnOiU1llNSY7lt+tAOfRdKKQYmRDAwIYILxnjejOMNep0gOBmYPHlykxj8xx9/nHfffReAnJwc9uzZ00IQZGRkMG7cOAAmTpzIwYMHXd77iiuuaDznnXfeAWDlypWN9589ezZxcXEefR6hd3KgsJItuSWcqLRQXFVHQXktR0urySuppqKmnsjQICJDg+gXE8bFp/bnnJHJhAUHcqLSwkdbj/L17gKOlVWTX1ZLYUUtVg3RoUGMTo3hf98d5IVVBxjeN5pdx8o5e1gS//jhOOIjQyipsrD+4AmOlFRTWGGurWvQBAUoAgMUEwfFcdm4VAJsmsJ5o/tx3uh+bj+XUorUPuGkNluBXzkxjSsnplHfYCUoUMqsOdPrBEFbK/fuIjIysvH9V199xbJly/juu++IiIhg+vTpLmP0Q0NDG98HBgZSXV3t8t728wIDA6mvNw6qnmbeE3xHbX0Dn20/zqI1h1i9v7hxv1IQHxFCSp8w0hMiiQkPpspST3lNPRtzTrB0+zFiwoIY3T+WdQeLqbdq0hMiSE+MZFRKDP1iwzljcAJZ6XEEBwZwvKyGV1Yf4tPtx/j5ecO4bfrQxom9T0QIs0b19dVXIELABb1OEPiC6OhoysvLXR4rLS0lLi6OiIgIdu3axerVqz3++VOnTmXx4sX86le/4rPPPuPEiRMe/wzh5MVSb+XDzXm8tvYwGuPATI0LJzosiKAAY9fOPVHNppwSdhwtw1JvZUB8OL84fzjnjupLYlQoseHBTWz1zjRYNav2FfJWdi7b88r40dQMLh3Xn1EpMa3mnPSNCeOe84Zzz3nDvfjkgqcQQeABEhISmDJlCqeccgrh4eH07etY7cyePZv//Oc/jB07luHDh3P66ad7/PPvv/9+5s2bxxtvvMHZZ59NSkoK0dHRHv8cwfdU1tbzzZ5CSqosVNc1UFRh4c3sHI6X1TI0OYrEqBA25pxgydaj1DuFwoQHBzImLZYbzxjEWZlJTB2a2LhCb4/AAMVZmUmcldm5aBXh5EeihnoBtbW1BAYGEhQUxHfffcett97Kpk2bunRPf/9Ou5uK2no2HS4hr6Sa6cOTSI5xxK7XN1hZe6CYtzcc4ZNtR6myNI01nzo0kZvPyuDsYUmNK3SrVWNpsFJv1dQ3WIkOa33FL/gHfhU15I8cPnyYq6++GqvVSkhICM8884yvhyS4QYNVs3h9Di9/d4hdx8oaY9kDFJyVmcS0YUlsyilhxfcFlFbXER0axCWn9uey8akMSoggPDiQMNtfcwICFGEBPTOHReh+RBD0AjIzM9m4caOvhyG0QX2DlUPFVUSHBhETHsyGwyd46MMd7DpWzqlpsfxsZiYTB8WRFB3Kx1uO8u7GI3z9fQGJUaGcO6ovM0ckM2N4creUGxD8DxEEguBlymrquOG5tWzKKWmyP7VPOE9cM4ELxvRr4nQdmRLD3ecO40hJNal9wt225QtCZxFBIAgeoMGqWXugmE+3HyMiJJAfTc0gMSqU0uo6bnh+LduPlPLrC0YQERJEWY0x8/wga4BLsw4Y086A+IhufgrBXxFBIAidRGvN5txS3srO4ZOtxyiqtBAaFEBdg5UXVx1k/pnpfLuviB15pTx57YQOJUUJQncigkAQ3GT5rnz25JdTbbFSaam3bVcQFhzArJF9uWBMCtOHJ5FXUsNjy77nya/2ERyoePLaiZzrwwQqQWgPEQQ+ICoqioqKCvLy8li4cCFvvfVWi3OmT5/OI488QlaWy2gvAB577DEWLFhARIQxIbhT1lroOFar5k9LdvLsygON++wFzh6+YgwXjE0hJsxRW35ochT/vmYCC88px1Jv5ZTUWF8MWxDcRgSBD+nfv79LIeAujz32GNddd12jIFiyZImnhibYqLY0cNcbm1i6/Rjzz0znnvOGER4c6FaZgmF9JalP6BmIIPAAv/rVrxg0aFBjY5oHHngApRQrVqzgxIkT1NXV8Yc//IFLL720yXXOfQyqq6u56aab2LFjByNHjmxSa+jWW29l3bp1VFdXc9VVV/Hggw/y+OOPk5eXx4wZM0hMTGT58uWNZa0TExN59NFHef755wG4+eabufPOOzl48GCr5a4Fw+GiKv67Yh8F5bXU1Fs5XFTJoeIqfnfRKH40NaP9GwhCD6T3CYJP7oVjWz17z35jYM7DrR6eO3cud955Z6MgWLx4MUuXLuWuu+4iJiaGwsJCTj/9dC655JJWa7M89dRTREREsGXLFrZs2cKECRMaj/3xj38kPj6ehoYGzjnnHLZs2cLChQt59NFHWb58eYu+A9nZ2bzwwgusWbMGrTWnnXYaZ599NnFxcW6Xu+7taK05XFxFn/AQYsKDqK238p+v9/HkV/sIVIpBCRGEBgfSv084v7lwlNj4hV5N7xMEPmD8+PHk5+eTl5dHQUEBcXFxpKSkcNddd7FixQoCAgI4cuQIx48fp18/15EjK1asYOHChQCMHTuWsWPHNh5bvHgxTz/9NPX19Rw9epQdO3Y0Od6clStXcvnllzdWQb3iiiv45ptvuOSSS9wud91b2VdQwXsbj/DepiPkFButKyo0iOBAxYmqOi4am8JvLhxJSqxoSYL/0PsEQRsrd29y1VVX8dZbb3Hs2DHmzp3LokWLKCgoIDs7m+DgYNLT012Wn3bGlbZw4MABHnnkEdatW0dcXBzz589v9z5t1Y9yt9x1b6K+wcrnO47z4qqDrDlQTICCKUMTWTBtCDWWBo6UVFNSZeHqSQM4c0jnu7oJQk+l9wkCHzF37lxuueUWCgsL+frrr1m8eDHJyckEBwezfPlyDh061Ob106ZNY9GiRcyYMYNt27axZcsWAMrKyoiMjCQ2Npbjx4/zySefMH36dMBR/rq5aWjatGnMnz+fe++9F6017777Li+//LJXnvtkpMGq2ZRTwrYjplXgyr2FHC2tIbVPOL+aPYIrJqTSNyas/RsJgp8ggsBDjB49mvLyclJTU0lJSeHaa6/l4osvJisri3HjxjFixIg2r7/11lu56aabGDt2LOPGjWPy5MkAnHrqqYwfP57Ro0czePBgpkyZ0njNggULmDNnDikpKSxfvrxx/4QJE5g/f37jPW6++WbGjx/vF2agvfnl3LN4M5tzSwFIiAxh/MA+PHjJaM4Z2VcqcAqCC6QMteCSnvadNlg1L3x7gL9+upvIkEDumzOSs4Yl0i8mrFUHvSD4E1KGWujVHCqq5OdvbmbdwRPMGtmXP11xCsnRYvoRBHcRQSD0WKxWzaI1h/jTkl0EBSoe+cGpXDkhVTQAQeggvUYQaK1lAvAQJ7O50GrVbMwp4fMdx/ls+zH2F1ZyVmYif71qrIR8CkIn6RWCICwsjKKiIhISEkQYdBGtNUVFRYSFnTymFXuJ50+2HWXptmPkl9cSFKA4fXACt88cyuXjRQsQhK7QKwRBWloaubm5FBQU+HoovYKwsDDS0tK69TO11ryVnUuDVTNzZDLJ0WFU1Nbz+trDvPDtQY6UVBMWHMCM4cnMPqUf04cnExse3P6NBUFol14hCIKDg8nIkDowPZW6Biv3vr2VtzfkNu4bkxrLoaJKymrqOS0jnvsuGMHMEclEhPSKf7KCcFIh/6sEn1JlqeenizawfHcBd80axnmj+/LFzuN8tbuAs4YlcctZgxk3QMpqC4I3EUEg+IyaugZueG4tGw6f4E+Xj+Ga0wYCpmfv7TMzfTw6QfAfRBAIPuMvS3ex/tAJ/jVvPBef2t/XwxEEv6X97hpdQCk1Wym1Wym1Vyl1r4vjg5RSXyiltiilvlJKda+HUvAZX+46zgvfmr6+IgQEwbd4TRAopQKBJ4A5wChgnlJqVLPTHgH+p7UeCzwE/Nlb4xFOHvLLavj5m1sYmRLDvXParsEkCIL38aZGMBnYq7Xer7W2AK8DlzY7ZxTwhe39chfHhV6E1ppdx8r42WsbqbLU86954wgLDvT1sATB7/GmjyAVyHHazgVOa3bOZuBK4J/A5UC0UipBa13kfJJSagGwAGDgwIFeG7DgHSz1Vp75Zj/vbTzCnvwKAhT85cqxDE2Wnr6CcDLgTUHgKtWzee2CnwP/VkrNB1YAR4D6Fhdp/TTwNJjqo54dpuBNymrq+MnL2azaV8TkjHh+f+loZp+SQlJ0aPsXC0JHsVohwKuuz16JNwVBLjDAaTsNyHM+QWudB1wBoJSKAq7UWpd6cUxCN5JXUs1NL6xjX0EFj159KldMkFgAwQWWKggK6/oEnv0iLHsQ5r0GA0/3yNB8Tlke1JY7tqOSITzO4x/jTUGwDshUSmVgVvpzgWucT1BKJQLFWmsrcB/wvBfHI3QD9u5gX+/O5/V1OVRZGnjxpslMzZQWkIILtIZnZ0FQKFz3NkTEd+4+NaVGCFQXwytXwQ3vQ9pEz44VzHgB2qptVbQPSnNh8Nld+6ziA/D4eJoYUi58FCb9uGv3dYHXBIHWul4pdTvwKRAIPK+13q6UeghYr7X+AJgO/FkppTGmoZ96azyC93lv4xEe+mgHxZUWAhRMGBjH7y87hZEpMb4emnCyUnII8reb9y9eBDe8Z1a9HWXlY0YIzHsDlv4KXrkcbvwQUk713Fgb6uH586FgF8QPhoShcOo8GHZe0/M++SXkrIN7D7UtMNojbwOg4bw/QkyK2ZcyrvP3awOvJpRprZcAS5rt+53T+7eAt7w5BsH71NY38NCHO1i05jBZg+J44JLRTMtMpE9EiK+HJgBUl0BwBASdhL/HwW/N6+yH4YuH4IUL4AcvQtJwCHSzqGBZHqx+CsZcDcNnQ99R5j7/u8wIFk8Jg/XPw5H1cMqVRgPZvxxy10PmFseEb6mCA99AQ60RcnHpnf+84ztABcLkW4zG5EUks1joMDV1Daz4voCiSgsnqix8svUYW4+U8v/OHswvzhtOUKA4604arA3wzAwIjYYffQrBPuzZkG9bSTsLpEPfQng8TP5/ZrW76AfwnykQEGQm0Ynz4cyftX3f5X8C3QAzf2u2+wyEGz+Aly6Bly6G696BNJcdGt2nshCW/wEyzoYrnzMT/4aX4YPb4dgWh7A5aBMCAMe2uRYEVitsfhX2fgEX/A0iWzGb5u80WoeXhQB4ObNY6H00WDW3LdrAgpezue+drfx16W7ySqp5+vqJ3DdnpAgBT5G7Hp45B755FKqKzT5rg5k8PvstVOS7d5/vP4Xi/XB0M3x4h8PG3d1kvwRPngZf/anp/oPfwKAzjaN40Blw67dw6ZMw5Q5QAfDdk23fN38XbFoEk26BuEGO/fGD4aYlRsj871I4uLLltQ118MXvoSSn5bHmfPEQWCphzl8dq//hc8wYd37kOG/P50b7QsGxrS3vk5sNz82C938K298xgq+2opVn2w7J3dM3XDQCoUM88tluvtyVz68vGMFFY/sTFxFCeIgfJoV986j5Tzp8jufvXX4MXr8WLBXGFLHib5B5HuSsgfKj5pzYgXDagvbvte5ZiE6BCTfA13+B/uPh9Fs9O96C3fD6NcY+nzi05fHNrxshpAJh8xsw8/8gINBMwCWH4fTbHOfGDXJM6JFJsPReKDvqsJE3Z9kDEBIF037e8lifgXDTJ0YQvHIl/HRN0xX6oVXwzSNGSF77Zuv2/CMbYMP/zDiTnTLhIxNh4Bmw6yOY+RsjZPd8CoOnQ+GeloJgxwew+HqI6guX/xdCY+CN62DxDXDNG01NYZZKOHEQxl3rekweRpZvgtu8v+kIT321j2tOG8iCaUPo3yfcP4WA1Qpf/xU+/rlZVXqSegssvhFqy4wp5yffwilXwP6vjOnkBy9BcKRZ5bdH8X7Y94Uxr5x9L4y4CD79DRxY4dkxr3sOivbC1jdbHtv2Drx3K2ScBZf8C8rzjDkIHK+Dpri+b6ot6idvg+vjh1bB95/A1LtajzaKSTHhpPU1sPuTpscOfmNe934O3y91fX11CXx0pxFK03/V8viIiyB/h4kUKtxjBFvmudBvDBxvJgi2vgkxqXD7ejh1Loy4AC5+zPxG7/+0qbaWv8u8dpNGIIJAcIttR0r55VtbmJwezwMXj/b1cHxL+VGor4ayXNj+nmfvvfReyFkNl/4b+p1i/i59wkSgXPM6jL7MmD2K97V/r/UvmFX4hBuM6eWyp4zN+fXrIG+jZ8ZbXwtbF5v3uz9ueqzkMLxzCww4Dea9DqMvN6v3LbbzD66EsD7Q9xTX9+43xvgKjmS3PKY1fP47iO7fvoaTMATih8C+5U33H1hhhGvicPO919U0PV6aC8/PNk7bi/8JYbEt7z3iQvO662PY85l5P/Rc87uVHDaCBMzi4eBKoy2EOUXRTbgBpt8HW94wgs2OPZIquXl5Nu8ggkBol5q6Bu58YxPxkSE8ed0EQoL8/J+NfRIODIFVj3vO7r7jfVj/HJy50ESmtEZ8RvsaQV0NbHzFTFQxtuquYTFw/TsQHgsvX+7aht1Rvl8K1SfMBHdsq5n87Gx6Daz1xgwSEgkhETDyYvOcdTVmYrT7B1wRHG4mwiMuNIKdH0DuOpjxa/cc4ENmmM+rt5jt2gojYIbMhDl/MWaY7/7lOP/YNnj2XCg7YvIbRlzg+r5xg6DfWGMe2vOZGW+fAWYfwHHbhJ6/3YS3pp/V8h6n32oE3t7PHfvyd0JQeNeijjqAn/+PFtzhn1/sYW9+BQ9fOZbEKCkNQZFNEEy5w0SM2E0Mzdm7DDa96t496y1mhZs8Gs65v+1zE4aYiauhRTUWBzveMxNP8+Sj2DQTXx8cYcIr7SaIzrLpVeODmPM3s203v1itxombMa2pE3fs1cbslf0inDjQulnITuoEYxpyFrYNdSZ5LGkkjLum9WudGTIT6iohd63ZPrzaCKmMaUZIjLwYVvwd3r0V/j3JRC6B8TG0lxg28mLIWWtMXUNnmX12LccubA/Y/o1kuBAEYbFGa9q7zLHv+HbjjwjoHtOrCAKhTbbklvD0iv1cnZXG2cOSfD0cz6E1fP8ZfH6/iTl/ZLhJSrJa27+2eB8EhsLUu43teNW/Wp5jtcLH98An97p3z+wXzOR+7oMQ2E4MR/xgM4mVthHtsv55YwbKcDGJxaXDDR+YSeaZmbDyH8bE0x5am8glO+XHTZTMqXMhaZgxseyymYcOrzJx9M2dnRlnG2fp8j+a7fT2BMFEE7PvrAFtfNn8BrMecH+iTJ9qzGT7vjTbB76GgGAzAQOc/yfjrN3zqTEjzfw/uOVLY+JpjxEXAtr8Jpm25LLofhCR6CQIVpjfLbaVMitDZ5lzy4+Z7fydZlHQTYggEFqltr6BX7y5haSoUH5zYffYKruNVY/Dqz+A754wjsTETFh2Pyy6CioK2r62aL8xz4REwOQFxiSQv7PpOYe/MxN7balxpDpjbWhaP6amzET0pJ/lWFG2RfwQ89qan+DEIRNhNP661iNhEofCjz83q91lD8CTZ7h2IlsqjaB743p4dCT8eYDxPWht7Nq6AU61rcpHXGBWxdUlRlMIiTarZWcCAuGUq4xWEBrjMKG0Rv8J5tXuJ9AaVv/H7B92ftvXOhMWC2mTHH6CAytgwGTzG4KJMPrFXvjFPuOLmfbz1iOVmpM8CuIyzPPaaxwp5XAYN9Sb7yVjWuv3sP/ue78wOQuV+d3mKAYRBIITZTV1/Obdrcx85Cum/XU5Ux5ezu7j5fz5ijHEhruZ5dkTyNto4sJHXgz35ZiV340fwkX/MP9hnzoDnjsP/pUFfx8Bu5Y0vb54n2MyzvqxseWufKzpOZsWmRUomBBQZ779J/wlw2gjtRVGKFUVwbkPuVeSIMEuCA64Pr7zQ/M6qp32HnGDTETNtW8DGl67pmVM++e/M3kLRzebVXXqBBNF8+Z8szJPm2S0AYDhF5hV8fZ3jRN99GXGN9CcsT8wrwNPb39FnzTCfL92P8Hh1VC425i8Olq+YcgM89sX7zcmveb2+qDQzpWEUApm/9n4GpxDQPudYhYIeRuM4HPlH2g8d4zRlPYuM1FIYDKkuwkRBH7Kb9/byo9eXMe7G3OprK1nxfcFnP+PFby29jBDkqOYOCiOGcOT+NPlY5gxohO1X04WKgrMJF1mi7+3VMLbN5v/dBc/7nA0KgVZPzJCIeVUMyn0HW3Ot0+sYMw8xQcgYbDZjkyAyTeb1XHeJrOvtsJMhKfOM6vE3GaCYNfHptrmt4/Bv7OMVjL6CjPJukNUXxNCWtSKRrDzQ+g7xpgi3CFzlokospSbJCc7lkoT9z92Lty5Ba581piUzrnffEbh901NP6lZEJlsNKu6SqORuCJlHEy8ySSBtUdgEPQf59AIsl8wmsToy917NmeGzAQ0LP8zaGvbK/SOMnwOjG9mBus3FhosJrwW2v48pYxWsO9LhzmpmyKGQBLK/JK1B4p5ZfVhokOD+HJXPqFBW6mttzIkKZK3bz2T8QM9X+a2S2x+w5RIaC1yoy22vG4mpq/+bFbvVYVmAr3xQ9ex531HmygRO6/+sGn4YlmuKSFg1wgAzvq5MYV89ltz3x3vm4lwwvXGju+sEdSUmhXi1Lth2Gz45Bdm3zn/5/4zKWULIXUROVR+zJiFpt/n/v3A2MqTRhon7oQbzL5t7xjhkHWT47yAADjrbuPk3fomjPlB02PDZ5vkq/ghDvu7q/Ff/JjrY67oP8FEU1XkGwE74XrXmoY79wmNNeMOCut62Yn2sDuMt71tNJv2iukNPcdokhsXmYzoqL7eHZ8TohH4GVprHvlsN0nRoaz+9Tm8+adQlgkAACAASURBVJMzmDtpAHefO4yPF57lPSFQ8L17TtPmVBbChwthdTulBlqjNNesnk+5CtY8ZVbuU+90Hb3hitQss/KtsbXJsK/CE5wEQXgfM/Ee/Mas9jctckyEaVkmAqSu2px7aJVZjQ4+GwZMgpu/hLt3ur96txOf4dpHsPNDQMOoSzp2P6VM4tmRbDi6xezLftFMYK4m9IGnwYWPQGhU0/3DbXH1467pWuVNZ1InGD/O5/cbITxxfufuExhk+921MUt5u4ZPYqYJKrDWuad9DJ5hSlbkbzcLEk99f24ggsDPWLm3kLUHirl9xlAiQ4OYlB7Pg5eewsJzMr3XP/jACnhikiNSpCOse85MArVlnfvs0lwT133ZE/DTtXDBIzD91+5fnzoB0I4ELPvk66wRgDF1JI2AJb8wfgb7RJiaZezmRzeb8/Z/bVuNTjbbAQFGkHSU1kJId34ACZlmLB1l7NVmbBteMuaJI+vNpNuRCSnzXFMz/7T/1/HPbw27yWzzqyaKqN+Yzt9ryAzz2pa93lMEBjscvu58XkS8+fcC3eooBhEEfoXRBr6nf2wYcycPaP8CT/HNo+b1238azcBd6qph7dPmfY0LQVBT5gi3a43SXEfIXmKmraRvB8ox9x9vXu3moaL9xnkZ3SyiJDDI1I0vzwOU8Q+Aw/xg9xMc+NqsRoPD3B+DK1yFkFYWmbLOoy7p3GoyIh5GXWYyf7970giFsT/s2D0CAo0jN9SD/ajjMhxduSbe1Pa57THiYhhweud8DJ2h3xhAGUe7O2Sea1670T8AIgj8ii925rM5p4SF52QSGtRNNYLyNpq67Wfcbuy6H9/tfibu5teNTT9pRNNwSzvLHjDRPW3dr+yIqe/SWSLizerfHrVSvM9Mwq6yYTNnmYl0zFUQa/vMqGRTIC53nbFx5+9wHdvfUVyFkO5eYsI5R3bQLOTMxPlG+9r8qnmWznYM8yRKGU0gJNrUXeoK0X3hx582Ne15kyl3whXPuP89jrrMLDLcFRweQpzFfsK+ggr+8PEO0hMiuHJiN/YOXvmYifI4+5cmwemjO42d/tS5bV9ntZpompRxxp6++qmW55TlmaSl4v2u/2PX1UBlAcR2UftJy3LE2Bfta1qBsjlXv+T6+tx1jnt0tYUhOHwKziGkOz8w8fBdacQy8HSTGFa4u/O2eG8w+2ETYtsZJ7EvSRzquiJrayQNg3u6mO3dCUQj8APezs7l4n+tpLS6joevHEtwd/UMKNpnJqdJPzYJPRNuNHHnn/7GmIk+WGhq3tjT753Z8ykU7TFNSUJjTBhe8+xXuwPXVa15MNoAOFbnnSV1oik0V3LY2OWb+wfaIy3LmHC2vmmiVjzRbjC6nykTYXdel+WZZKmRnTQL2VHKNHg59ZqTqwF8YubJNZ5ehgiCXkxtfQP3LN7MPW9u5pTUWJbccRanD07ovgGsetyk8Z9mqw4ZEGCStmpKTaLSro+MTXvjyy2v/e4Js5IfdZmj6mNzP4HdgWwvZ9yc0lzz2lpav7vYyyFvf89EgHTUrGB3AH6/1Kj8nqgf0zyE9JtHAW0ynbvKqEvg8qe6NWpF8C1iGuqlVNTW85OXs1m5t5CFM4dyx6xhBAZ043/sinwTWz/uWmOXtdNvDNy51ThLw+NMA5actU2vra0wYZZT7zROWLvjsbYMopzqHTVqBN8aP0HzicuuEXTFRwAmHjwg2FFuuaMaQcpYU13SWu8Zs5Cd+MHG51CaayJ9xl3btMCbILiJaAS9kKKKWq59ZjXf7S/ir1eN5e7zhndNCNTXmszc6hPuX7N7iTHnTHaRPRqT4ogCGXCaqULp3Hoxd61xetorU4ba6rc3DyGtKTM5AmW5xlfQHLtG0FVBEBxmBJg947OjGkFwuCO5yBOOYjv2ENIVfzOC0FWXLkFwA9EIehllNXVc/d/vyD1RzX+vm8isUZ3MTizJMeab7z81WbIAEQlw9y73wi/3LoOYtPbD4OzJSjlrYeRF5v2hVaZOzwBbrH2jRuAUOWS1GsEw8iKTRHXw25a120tzTXXQroZqgjEP5W0wjVU6k/E59BzTejJpeNfHYsceQpr9knHs9hnouXsLfoVoBL0IrTW/fmcrB4uqeOGmSZ0TAnU18PXfTE323UtMktHM35q6MFVFcHRT+/doqDOJU0PPad/OnHKqafCSs8ax79Aqs98uAOwdnZx9BJZyQBtBEh7v2mFcdqTr/gE7dj9BfEbnbOczfgO3rvKs3d1uogoIgrPu8dx9Bb9DNIJexJvZuXy05Sg/P28YZw5J7PgNrFZ47YemP+7IS+D8PzpWmZWFsO4ZM+HaV+qtkbPWrNbtyTFtERxmomjsfoK6GpN85WxScqUR2P0DYX1MTftDLgRBaa4JWfUE9sSwjvoH7AQEer7JiP3ZJlxvsqcFoZOIRtBL2FdQwQMfbOf0wfHcOr2Tk9+qx40QuPBR+OHLTU0NkYkmsau1CB1n9n5uVqnuVnccMNkkntXXGvNLQ23TzlWhtqghZx+BXTsIi4FBU01oZ4lTlq3WtqxiD02Q8ba+twPP8Mz9PEF0X1Pk7rw/+HokQg9HNIIeitaa7EMn2F9YyfHSGj7YnEdIUACP/XB85xzDeRvhy9+bGvZZP3J9zqApJhmsob7tLlp7lxmTjatm364YMBm++7cpdmYXNM4x43aNwNk01KgRxDqSqw59C33mOo5bKrqeQ2AnIAAWuuid62s8WUpZ8FtEEPRAtNb88eOdPLvSkVWaFB3KP64eR7/YTjhGm9To/2frduz0KaYc8NHNkDbR9Tnlx0x0TXt9d52xF2DLWWP8A8mjm6bkB4WYujfOGoH9fWiMOT+sjzFb2TOWPRU6Kgh+gAiCHoDWGmWbnK1WzW/f38araw5z4xmD+PHUwSTHhHatcuiXfzAZqvM/coR1umKQrf7JoZWtC4K9X5hXd1ou2olJMWaoQ6vg8BrXDclDo5uZhpw0goAAo604N5EvtWcVi+1cENpDBMFJzuc7jnPbomwyk6OZOCiOwopaPtl2jNumD+EX5w9vFBBNKDtqbPrObfPaIne9yXhtr9BVdF9T4vjgtzDlDtfn7F1mNIuOlgoecJpphKIbYNCZLY+HxrTs8wsO89OQGbD7YyjcY8oR2Ktyeso0JAi9GHEWn8TUNVj505Kd9I0JIz4yhHc25PLJtmP8/Lxh/HL2CNdCoCQH/nmq67INrX5QlSNpqz3Sp5jG7NaGlsca6k2rvaGzOh4mOeA0IwTAtSAIi3HtI7CPe9hs87rrY/NadsQ4rLuxy5Mg9FREIziJWbw+hwOFlTx7QxazRvWlvsFKWU098ZFtJHStf95E3bTW2NwVdVWO3r3tMWiq6Vx1bKvpJevM1jehpqRjZiE79pDU+CGmoFpzQqObagS1paYvgD25rc8A0yN29xJTmqI0F6L7ez5kUxB6IaIRnKRUWep5bNkeJqXHcc5I0+s0KDCgbSFQV2NqzoBJ/nIXSxWERLh3brotrNM5gctqheV/gvd+Ygqs2VfnHcHu8G0tCiY0pqWPoHlU0ogLTT5CRb7xEXgqmUwQejleFQRKqdlKqd1Kqb1KqXtdHB+olFqulNqolNqilOpEd/LeyfMrD1BQXsu9c1oxAbli+ztGAASFmTr87lJXbWr2uENMf9Mx6tC3JoM4byMsvh6+/ospejb/Y/eFijOBQXDzFzDrAdfHXfkIwpqZs4ZfAGhT5bM0R/wDguAmXjMNKaUCgSeAc4FcYJ1S6gOt9Q6n034LLNZaP6WUGgUsAdK9NaaeQnGlhf9+vZ9ZI/sycZCbnY20hjX/NUlfMf1NJrC71FW6bxoCoxVsfgP+PADqq01doNl/MX1qu1JCoa0GHq58BM01gn5jTDewXR+b+vyiEQiCW3jTRzAZ2Ku13g+glHoduBRwFgQasC/rYoE8L46nR6C15v/e20ZVXQO/nN2BAmW5600doAv/DjnroHCve9c11JnCZR1ZxY+/Hk4cMhNvWpbJto3p7/71ncEePmovN11bZkxJzigFw+fAumeN41lyCATBLbwpCFIBp5x/coHTmp3zAPCZUupnQCTg0suolFoALAAYOLB3V1h8buUBPt56lPvmjGBY3w40AF/7X2M+GTvXOIqr3NQILLbKosEdEAQDTzc5B91JaAygTbZwaLTRCPq4qL0/4gLzXYDkEAiCm3hTELiyETTvMj4PeFFr/Xel1BnAy0qpU7TW1iYXaf008DRAVlaWm53Pex5rDxTz5092MXt0PxZMG9z2yTVlJhu4NMf0CSg/Bqf9BEKjTA5BXZWZ5Nvr8VpXbV47Igh8gXOZidBo1z4CMIllobEmqkh8BILgFm45i5VSbyulLlRKdcS5nAs4L8nSaGn6+TGwGEBr/R0QBnSibGbPJ7+shp++uoGB8RH89Qdj23cQH15t+vpGJplwzal3wVl3m2MRtq/QHT9BXZV5PdkFgX3StzuMXfkIwCTR2aueimlIENzCXY3gKeAm4HGl1JuYVfyudq5ZB2QqpTKAI8BcoHntgMPAOcCLSqmRGEHQgXCX3kFOcRU3PL+Wipp6Xv7xZGLC3MgIzre5Wq5+qWVZiEhbO8fKwvZbF9oFQWcifboT5y5ldTUmV6K1JLhpP4fkkW2XyxAEoRG3BIHWehmwTCkVizHnfK6UygGeAV7RWte5uKZeKXU78CkQCDyvtd6ulHoIWK+1/gC4B3hGKXUXxmw0X2vda00/rth2pJSbXlyHpd7Kyz+ezIh+bmb45u80CVOuJrtIm0bgjp/AYtcIOhA15AucBUFts/ISzUkeaf4EQXALt30ESqkE4DrgemAjsAiYCtwITHd1jdZ6CSYk1Hnf75ze7wCmNL/OX9i0fQePLf6UoLCxLPrJGR1zDufvaH2yswsCd3IJGk1DbuYR+ArnLmXN6wwJgtAl3BIESql3gBHAy8DFWuujtkNvKKXWe2twvZmC8loK3rqbx9VWKm/bS0psB1bk1gYo2N16Fm6nfAQnu0bg1KXMufKoIAhdxl2N4N9a6y9dHdBaZ3lwPH6B1ar59Rtr+Kd1AxGqlphoN5rBO1N8wNjIW2sMHxJp6vC4YxqyRw21F13ka5qYhkQQCIIncTcKaKRSqjF7RykVp5S6zUtj6jW05u54buUBAvZ/SYSqNTuca+i4g91R3JppSCljHmquESy+EdY913RfYx7BSa4RhEQBqqlG4G7FVEEQ2sRdjeAWrfUT9g2t9Qml1C3Ak94ZVs/mUFElt76ygbzSas4YnMC5/WsZGBvMifCBFJTX8tdPd/FK/BaosF1QU9axCJf8nYCCpDYyjyMSmgqChjrY+aEJr5z0Y8f+npJHEBDgyB8QH4EgeBR3BUGAUkrZI3psdYQ6aM/wD9bsL+Inr2Rj1XDOiGRW7y/iyt2/Jz1gH/NrH6WCCDLigphsWWts+VWFjhWuu+TvgLj0ts05kUlNncWlOabsQm1F0/PqOpFZ7CvsZSYafQSiEQiCJ3BXEHwKLFZK/QcT5vkTYKnXRtVDeTs7l3vf2cKA+Aieu3ESGYmRaK2xPPUQofllfDk5m7Kpv2VA0UrUG+Uw8UbTtL3DpqGdrfsH7EQmQoFTqoe9P4GlmSCwVIEKgKDQjo3BF9hLUdeWmTGHRPl6RILQK3DXR/Ar4EvgVuCnwBfAL701qJ5I9qET/PLtLUxKj+fdW6eQkWhW60opQutNNmzy9ucYGlxI6PcfQUg0jLzEXFzTAUFQXwtFe9uPk49MNBqB3U9RvN+8Nhc6ddVGG+hK1dDuotE0VGqEQk8YsyD0ANxNKLNisouf8u5weial1XUsfG0jKbFh/Of6iS0zg2tKYdgc2P8VfPZb06R92PkQleQ47i6Fe4yJpz1BEJEI9TXGGRwaBScOmv2uTEM9wSwExhRUVWyrMyT+AUHwFO7WGspUSr2llNqhlNpv//P24HoCWmt+8+5WjpXV8Pi88S2FgNZmok8eaRq+7/zQNI8ZdYkpjgZtm4YqC2HlPxxO3fyd5rVd05C9zITNT9Caaaiu+uSPGLLj7CMQ/4AgeAx3TUMvYLSBemAG8D9Mcpnf82Z2Lh9tOcrd5w5jwkAXkT911WCtMyvYKQshOsXE+A+d1TRbtjW+ehiWPQBf/dls5+8wTdkT2mjiAk5lJmwtK0/YBIFzly9wr0LpyYK9S5mrXgSCIHQadwVBuNb6C0BprQ9prR8AZnpvWD2D7Xml/O79bZwxOIGfnD3E9Uk1JeY1LNZMuD94CS5/yrwPDDZmGfs5zakqho2vmPIPq/5t2kLm74SETEfT9tZwLjOhtcM0VFdlMpPt9CSNwN6lzO4jEATBI7grCGpsJaj3KKVuV0pdDiR7cVwnPUUVtSz4XzZxESE8Pm88gQGtOC6bl0MYeBqMvtxxvHlTdmfWPWdaQV7/jjH1vP8zOL7NvYJqzmUmKo4bARCXYfY5awV1VT3HRxAaY76PqiLxEQiCB3FXENwJRAALgYmY4nM3emtQJzt1DVZuXbSBwopa/nv9RJKi2wi9bK8uTvNevI0fUmM6bQ0913QEu/AROL7V5AO05x+AphVI7f6BfmPMq7OfoKcJAjBNeMRHIAgeo11BYEseu1prXaG1ztVa36S1vlJrvbobxndS8tCHO1h7oJiHrxzD2LR2bNV2QRDeynlhsa6jhrYuNmadM39mtkde7Ag3dUcjCIk0E3xlocM/0G+seXWOHLJUnfy9COzYC8+hRSMQBA/Sbvio1rpBKTXRObPYn3nh2wO8vPoQC6YN5vLxae1fUG33EbQiCEJjWvoIrFbjE+g3tmmF0QsfNY1mBk93b7D2ekPFB0wCVl+bJtHENFTdczQCZy1AfASC4DHczSzeCLxv605Wad+ptX7HK6M6Sfl8x3Ee+mgH547qy69mj3DvIndMQyWHm+7b/yUU7oYrnm2aNBWVBOf9wf0BR9iSyqz1EJvmqGdkcRYEPSiPINSpX4NoBILgMdwVBPFAEU0jhTTgN4Jga24pC1/byJjUWP45d1zrzuHmtCcIQmNamoaObjGvIy7o3GDtRCZBxTGjccRlONX0d/YRVPcg05CTFiA+AkHwGO5mFt/k7YGcjGit2Z5Xxodb8li8Lof4yBCevTGLiBC3G7uZSTjYFirqirDYllFDlYWmjk5X4/sjE02UUV21SWCz1+axm4asDSb7uMdoBM6CQDQCQfAU7nYoewGjATRBa/0jj4/oJGFvfjm3LdrA98crCApQTBmayP9dNIrk6LCO3aimpO1JKyzGTMb1FkduQGWBI+qnK0Qmmggb3QDxgx0TqT1qqKeUoLYjPgJB8AruLm0/cnofBlwO5Hl+OCcHe46XM++ZNQD86fIxzD6lH/GRnay6XVPatiBwLjMR5JQEZi8R0RUiEo0QAJtpqJlG0FPaVNoRH4EgeAV3TUNvO28rpV4DlnllRD5m97FyrnlmNcHKyscTs0kYMwEiutB6oT1BYD9WU+qUDVwIfQZ0/jPtOGsV8Rmm1HRAcEtB0FNKTASFmfHbS3YIguAR3E0oa04mMNCTAzkZyCupZt4zqwkKVLx1ZRwJa/4CW97o2k1rSlvPIQCnekNODmOPmYactIq4dPMaGu0wDVl6mEaglOP7EtOQIHgMd6uPliulyux/wIeYHgW9iseWfU9FTT2v3nI6aZE2l0juurYvqqs2cf+t0a5pyKkpO5h7VRV6yDSUYF4jkxxmldAoR9RQo2moh2gEYJ4jKLz9WkuCILiNu6ah6PbP6tnsL6jg7Q1HuOGMQQxJioK9tskyd33rFx1aBa/NM2aXS590JGw5U92es9jJNATGuWyt94wgsN/DXmMITEOcnuojACM462p8PQpB6FW4qxFcrpSKddruo5S6zHvD6n7+sWwPIYEB3DbdVt7ZPkmWHGraBN7O9nfhf5dBRDyU5MB/p8GKv5km8XasVlvJ5HaihsBRb8j+WR4RBDbzUryTIAiNdiSU2U1DPSWPAIwgkBwCQfAo7voI7tdaNxqxtdYlwP3eGVL3s/NoGR9uzuNHU9MdBeQslY4TmmsFq/8Db94E/cfDzV/AT9eYOP0v/wBf/t5xnqUCtLXt2vnNTUP2RjKe8BEEh0P6WTDkHKfPc2Ua6kGCIH1K07IbgiB0GXfDR10JjA5kVZ3c/P2z74kOC2LBWU49BZwrdB5ZD8Nnm/elubD0Xhg2G37wgsOsctXzcOIQ5G1yXNdeVjHYBIFynNsoCDygEQDM/6jpdkiUGSf0TEEw49e+HoEg9Drc1QjWK6UeVUoNUUoNVkr9A8j25sC6iy25JSzbeZz/N20wsRFO2b92jSAuo6lGsP09QMP5f2xpW49Ng7Ijjm3npjStERDgaMoOnhcEzXGOGuppCWWCIHgFdwXBzwAL8AawGKgGfuqtQXUnL646SFRoEPOnZDQ9YLefZ0yDI9mOyKDt75iqoAkuOpLFpkHpEdMRDNzTCKBpc5rKQkBBeHynnqddQp2cxXZh15N8BIIgeBx3o4YqgXu9PJZup7jSwkdbjjJ30gCiQpt9FZYKs1IeMBk2vARFe0xC1pFsmPWA6xvGpJoOWtUnjBPZXUEQFtPUNBQRD4FesrzZNQKr1aERBPWgqCFBEDyOu1FDnyul+jhtxymlPvXesLqHN9fnYKm3ct3pg1oetDd1T80y27nrTaQQNG016UxsqnktzTWv7TWlsePcnMZT5SVaw154rq7S/AWFG/OUIAh+i7szQKItUggArfUJ3OhZrJSarZTarZTaq5RqoVEopf6hlNpk+/teKdVKF3fPY7VqFq05zOSMeIb1dZEmYRcEicOM6eaITRCkTnRk6TYnxtaoxu4nqHbDRwAtTUPeFATO9YZ6UuN6QRC8hruCwKqUaiwpoZRKx0U1UmdsLS6fAOYAo4B5SqkmGVda67u01uO01uOAf9GN/Q1W7CngcHEV17vSBsDWyzfSrJZTJ8Cuj+HoZhh9Res3bU0jaK8cQnPTkCdCR1ujMVy1wtamsgdlFQuC4BXcNUT/BliplPratj0NWNDONZOBvVrr/QBKqdeBS4EdrZw/j27MTXhl9SESo0I5f3Q/1ydYKhyTZGoW7P/KvB/dRh5dZLIpimbXCGpKzcQbENj2YMJim0YNRXhRENhNQ5Zym7ATjUAQ/B23NAKt9VIgC9iNiRy6BxM51BapQI7Tdq5tXwuUUoOADOBLd8bTVXKKq/hiVz7zJg8gJKiVr8BuGgJIs/kJBpxuIoNaIyAAYlJM5BDY6gy14x8Ah2mo3mJCTrvNNFQloaOCILjdmOZm4A4gDdgEnA58R9PWlS0uc7GvNXPSXOAtre3F81t8/gJsGsjAgV0vevrNnkK0hismtDGpW6ogqq95nzbZTJjj5rV/85i0phqBO+WSw2JMfaFSm9z0qmnIqV1lT2pcLwiC13DXR3AHMAk4pLWeAYwHCtq5JhdwLqqfRuvNbOYCr7V2I63101rrLK11VlJS11fLhRW1AKT2acMs4mwaikyAu3fAhBvbv3lsqpOPoJ2Cc3bs5xTts31eN0QNWSpsWo8IAkHwd9wVBDVa6xoApVSo1noXMLyda9YBmUqpDKVUCGay/6D5SUqp4UAcRsPoFoorLUSHBbVuFoKmpiGA8DhTD789YlKhLM/E6burEdgduMXdIAgaNQKJGhIEweCuszjXlkfwHvC5UuoE7bSq1FrXK6VuBz4FAoHntdbblVIPAeu11nahMA94XWvdZhSSJymqtJDQXuvJ5oLAXWLTTAetyoL2m9LY6U6NoIkgqOxZvQgEQfAK7mYW2zOoHlBKLQdigaVuXLcEWNJs3++abT/g1kg9SFFFLQlRoa2fYG0wGcJ2M0pHiLH5w8tyO64RFO01r970EQSFgQq0mYYkakgQhE5UENVaf93+WSc3xZUWBsS3YRvvSlVOey5ByeH2exHYsZ9TvM+En3qzH69SjnpDddWSRyAIQqd7FvdoiiotJEa1YRpqLMbWiUnSnl2cv9O8uhs1BKbBTWSSe76IrtAoCCR8VBAEPxQEVqumuNJCfFs+gkZB0AnTUES8Mb8c32623c0jAEB71yxkJyTKVuVUi2lIEAT/EwRlNXU0WDXxkW34CLqiEShl/AT5tgRqdzSCkEhjtwfvOorthEZDxXHHZwuC4Nf4nSAoqrQAuGka6qTZJDYVig+Y9+4IAqUc5qFuEQRRUJFv3otGIAh+j/8JggojCLxmGgKbn8AWDeuu49duHuo205AtH1B8BILg9/idICiuNFnFbQsCWyvHzppNYp1KKrkrCOzndYtGEAP2ah4iCATB7/E7QeAwDbXhI+hqU/cYJ0HgTkIZdLMgcNJ0pMSEIPg9/icIbKahuAgvmobsFUpVgPv3CO1GH4HzmEQjEAS/x0uNcU9Cqoqh/BjFFVY36gx10TQU09+8hsW6nxMQ1o0+glCnjmwiCATB7/EfjWDDS/DUGZRVlLdtFgJTegHV+Ygau2moIxnCvjINSdSQIPg9/iMIbOaQqvLSth3F4Cg419kM37BY83nuJJPZCY83pqRu0QicWmdKHoEg+D3+YxqyTXi1laXEJ7Uz2Tr3IugMShk/QUc0gqwfQerE7lmhh4hGIAiCAz8SBGbyq60up19byWTQ+RLUzpz7UMfs71FJkDmra5/pLqHiLBYEwYEfCQIzsddXl7dvGqqr6rogGHZ+1673JnZncUAwBAb7diyCIPgcv/MRhOnqtusMgTEN9eaGLSE2QSA5BIIg4FeCwEzskdS0XWcIPGMaOpmxm4bELCQIAv4kCGyTX6SqcT9qqLdiNw2JIBAEAX8SBDbTUAQ1JLRrGqrqfFZxTyA4woSqiiAQBAG/EgR201AtCe2ahip6t/1cKSPoevMzCoLgNv4jCILCsBJAhKppu84Q9H7TEBjzkOQQCIKAP4WPKoUlMIJ4atuuM9RQDw21vds0BCaTuSMJb4Ig9Fr8RxAA7t1tPAAADAZJREFU1SqMuKC6tk+q60Kbyp7EZU82TSwTBMFv8S9BQBixgZa2T7KXoO7tjtSUsb4egSAIJwn+4yMAKnQYMQG1bZ/U1V4EgiAIPQy/EgRl1lCiAmraPsniJ6YhQRAEG34jCKxWTWlDKBG4Kwh6uWlIEATBht8IgrKaOip1KGG6uu0TxTQkCIKf4TeCoKjSQqUOI9TaniDoYptKQRCEHob/CIIKC1WEEVRf1faJdbbjIggEQfAT/EYQFFfWUkEYgfVVYLW2fmJj+KgIAkEQ/AO/EQRFlRaqdBgKDfVtmIfENCQIgp/hVUGglJqtlNqtlNqrlLq3lXOuVkrtUEptV0q96q2x1NZZqQu01daxr/pdYakEFQhB7VQoFQRB6CV4LbNYKRUIPAGcC+QC65RSH2itdzidkwncB0zRWp9QSiV7azw/mpoBUZPhveehthyiWvkoewlqpbw1FEEQhJMKb2oEk4G9Wuv9WmsL8DpwabNzbgGe0FqfANBa53txPI7aOm1qBL28BLUgCEIzvCkIUoEcp+1c2z5nhgHDlFLfKqVWK6Vmu7qRUmqBUmq9Ump9QUFB50dkt/u3ZxoS/4AgCH6ENwWBK9uKbrYdBGQC04F5wLNKqT4tLtL6aa11ltY6KykpqfMjCnFHIxBBIAiCf+FNQZALDHDaTgPyXJzzvta6Tmt9ANiNEQzeoVEjqGj9nLpe3qZSEAShGd4UBOuATKVUhlIqBJgLfNDsnPeAGQBKqUSMqWi/10bUqBG0IQgsFb2/BLUgCIITXhMEWut64HbgU2AnsFhrvV0p9ZBS6hLbaZ8CRUqpHcBy4Bda6yJvjUlMQ4IgCC3xamMarfUSYEmzfb9zeq+Bu21/3scd05BFTEOCIPgXfpNZDJgkMRUo4aOCIAhO+JcgUMqs9mvb0gjENCQIgn/hX4IATFJZaxpBvQWsdSIIBEHwK/xPEIREtu4jqJOmNIIg+B9+Kgha0QgaS1CLj0AQBP/BDwVBVOsagTSuFwTBDxFB4ExjLwIxDQmC4D/4oSBowzRUdtS8RiZ233gEQRB8jAgCZ45tARUAyaO6d0yCIAg+xA8FQRt5BEc3Q+IwSSgTBMGv8D9BEBplwkRdNbA/ugVSTu3+MQmCIPgQ/xME9oiguqqm+yvyoTwP+o3t/jEJgiD4EP8VBM39BEe3mFfRCARB8DP8UBC00pPg2Gbz2m9M945HEATBx/ihIGilFPXRzRCXDuEtOmUKgiD0avxQELTSnOboZjELCYLgl4ggAKgugRMHRRAIguCX+KEgcGEaOrbVvPYTQSAIgv/hv4LAOansqM1RnCKho4Ig+B/+JwhCo82rs2no2BaI7g9Ryb4ZkyAIgg/xP0HgyjR0dLNoA4Ig+C3+JwgCQyAgyKERWKqg8HtxFAuC4Lf4nyBQqmm7yuPbQVtFEAiC4Lf4nyAACIl2aAQHvzGvqVm+G48gCIIP8VNB4KQR7P3ClJWI7uvbMQmCIPgIPxYElVBTBjmrYegsX49IEATBZ/i3IDjwNVjrYei5vh6RIAiCz/BTQWDrUrZ3GYTGwIDJvh6RIAiCz/BPQRAaBZZy2LMMBp8NgcG+HpEgCILP8E9BEBIJJYehLFf8A4Ig+D1+KgiiTO4AiCAQBMHv8VNBYCszkTQSYtN8OxZBEAQf41VBoJSarZTarZTaq5S618Xx+UqpAqXUJtvfzd4cTyP2ngRDz+mWjxMEQTiZCfLWjZVSgcATwLlALrBOKfWB1npHs1Pf0Frf7q1xuMSuEYhZSBAEwXuCAJgM7NVa7wdQSr0OXAo0FwTdz7DzofRuSJ/q65EIgiD4HG+ahlKBHKftXNu+5lyplNqilHpLKTXA1Y2UUguUUuuVUusLCgq6PrLYNJh1v4SNCoIg4F1BoFzs0822PwTStdZjgWXAS65upLV+WmudpbXOSkpK8vAwBUEQ/BtvCoJcwHmFnwbkOZ+gtS7SWtfaNp8BJnpxPIIgCIILvCkI1gGZSqkMpVQIMBf4wPkEpVSK0+YlwE4vjkcQBEFwgdecxVrreqXU7cCnQCDwvNZ6u1LqIWC91voDYKFS6hKgHigG5ntrPIIgCIJrlNbNzfYnN1lZWXr9+vW+HoYgCEKPQimVrbV22YHLPzOLBUEQhEZEEAiCIPg5IggEQRD8nB7nI1BKFQCHOnl5IlDoweH0FPzxuf3xmcE/n9sfnxk6/tyDtNYuE7F6nCDoCkqp9a05S3oz/vjc/vjM4J/P7Y/PDJ59bjENCYIg+DkiCARBEPwcfxMET/t6AD7CH5/bH58Z/PO5/fGZwYPP7Vc+AkEQBKEl/qYRCIIgCM0QQSAIguDn+I0gaK9/cm9AKTVAKbVcKbVTKbVdKXWHbX+8UupzpdQe22ucr8fqaZRSgUqpjUqpj2zbGUqpNbZnfsNWAbdXoZTqY2votMv2m5/hJ7/1XbZ/39uUUq8ppcJ62++tlHpeKZWvlNrmtM/lb6sMj9vmti1KqQkd/Ty/EARO/ZPnAKOAeUqpUb4dlVeoB+7RWo8ETgd+anvOe4EvtNaZwBe27d7GHTQtY/4X4B+2Zz4B/Ngno/Iu/wSWaq1HAKdinr9X/9ZKqVRgIZCltT4FU9l4Lr3v934RmN1sX2u/7Rwg0/a3AHiqox/mF4IAp/7JWmsLYO+f3KvQWh/VWm+wvS/HTAypmGe1d397CbjMNyP0DkqpNOBC4FnbtgJmAm/ZTumNzxwDTAOeA9BaW7TWJfTy39pGEBCulAoCIoCj9LLfW2u9AlOa35nWfttLgf9pw2qgT7NeL+3iL4LA3f7JvQalVDowHlgD9NVaHwUjLIBk343MKzwG/BKw2rYTgBKtdb1tuzf+3oOBAuAFm0nsWaVUJL38t9ZaHwEeAQ5jBEApkE3v/72h9d+2y/ObvwgCd/on9xqUUlHA28CdWusyX4/HmyilLgLytdbZzrtdnNrbfu8gYALwlNZ6PFBJLzMDucJmF78UyAD6A5EY00hzetvv3RZd/vfuL4Kg3f7JvQWlVDBGCCzSWr9j233criraXvN9NT4vMAW4RCl1EGPym4nREPrYTAfQO3/vXCBXa73Gtv0WRjD05t8aYBZwQGtdoLWuA94BzqT3/97Q+m/b5fnNXwRBu/2TewM22/hzwE6t9aNOhz4AbrS9vxF4v7vH5i201vdprdO01umY3/VLrfW1wHLgKttpveqZAf5/e3cPGkUQhnH8/4gQDBE/QBsLJQoigkZtAioE0qWyUAJqFLG0sRNREe0tA6aMGkQCRsRKTBFIIVFD/CCIX4WmsJNACkXiazFzEvPlCV5OMs8Pltsbdvd2mLt9d+d234mIz8AnSdtzUTswzjJu6+wj0CqpMX/fK/Ve1u2dLdS294ET+e6hVmCy0oVUtYgoYgI6gDfAe+BCvfenRnU8QLokfAGM5amD1Gc+CLzNr+vrva81qn8b8CDPNwMjwDugH2io9/7VoL4twNPc3veAdSW0NXAFeA28Am4CDcutvYHbpP9AvpPO+E8v1LakrqHufGx7Sbqj6q8+zykmzMwKV0rXkJmZLcCBwMyscA4EZmaFcyAwMyucA4GZWeEcCMyWkKS2SoZUs/+FA4GZWeEcCMzmIem4pBFJY5J68ngHU5KuSRqVNChpQ162RdLjnAt+YEae+G2SHkl6ntfZmjffNGMcgb78hKxZ3TgQmM0iaQfQCeyPiBZgGjhGSnA2GhF7gSHgcl7lBnAuInaRnuyslPcB3RGxm5QPp/LY/x7gLGlsjGZSviSzuln550XMitMO7AOe5JP1VaQEXz+AO3mZW8BdSWuAtRExlMt7gX5Jq4FNETEAEBFfAfL2RiJiIr8fA7YAw7Wvltn8HAjM5hLQGxHnfyuULs1abrH8LIt193ybMT+Nf4dWZ+4aMptrEDgsaSP8Git2M+n3UslweRQYjohJ4Iukg7m8CxiKNA7EhKRDeRsNkhqXtBZmVfKZiNksETEu6SLwUNIKUgbIM6TBX3ZKekYaGaszr3ISuJ4P9B+AU7m8C+iRdDVv48gSVsOsas4+alYlSVMR0VTv/TD719w1ZGZWOF8RmJkVzlcEZmaFcyAwMyucA4GZWeEcCMzMCudAYGZWuJ+OvXcP6TkLpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8203098,
     "status": "ok",
     "timestamp": 1594870080952,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "dFJLAzliRFJz",
    "outputId": "bc985298-1c87-45f4-a361-574ed5ba99ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setupmodel()\n",
    "json_filename = \"baseline_model.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(json_filename, \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json \n",
    "json_file = open(json_filename, \"r\") \n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close() \n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "loaded_model.load_weights(\"checkpoint-baseline-smalldata.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics - F1, Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Evaluate ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:16<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00833964 0.99166036]\n",
      " [0.99667969 0.00332031]\n",
      " [0.99667969 0.00332031]\n",
      " ...\n",
      " [0.56331781 0.43668219]\n",
      " [0.89003888 0.10996112]\n",
      " [0.99667969 0.00332031]]\n",
      "[1. 0. 0. ... 0. 1. 0.]\n",
      "[1 0 0 ... 0 0 0]\n",
      "[1. 0. 0. ... 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"== Evaluate ==\")\n",
    "\n",
    "output_score = []\n",
    "output_class = []\n",
    "answer_class = []\n",
    "\n",
    "for i in trange(len(test_generator)):\n",
    "    output = loaded_model.predict_on_batch(test_generator[i][0])\n",
    "    output_score.append(output)\n",
    "    answer_class.append(test_generator[i][1])\n",
    "    \n",
    "output_score = np.concatenate(output_score)\n",
    "answer_class = np.concatenate(answer_class)\n",
    "\n",
    "lst = []\n",
    "for i in output_score:\n",
    "    val = i[0]\n",
    "    sublst = [1-val, val]\n",
    "    lst.append(sublst)\n",
    "    \n",
    "output_score = np.array(lst)\n",
    "\n",
    "print(output_score)\n",
    "print(answer_class)\n",
    "\n",
    "output_class = np.argmax(output_score, axis=1)\n",
    "\n",
    "print(output_class)\n",
    "print(answer_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1000.0\n",
      "2000\n",
      "806\n"
     ]
    }
   ],
   "source": [
    "print(len(answer_class))\n",
    "\n",
    "cnt = np.sum(answer_class)\n",
    "print(cnt)\n",
    "\n",
    "print(len(output_class))\n",
    "cnt2= np.sum(output_class)\n",
    "print(cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.94      0.85      1000\n",
      "         1.0       0.92      0.74      0.82      1000\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.85      0.84      0.84      2000\n",
      "weighted avg       0.85      0.84      0.84      2000\n",
      "\n",
      "[[936  64]\n",
      " [258 742]]\n",
      "AUROC: 0.943088\n",
      "THRESH:  0.18330988288008504\n",
      "test_acc:  0.839\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(answer_class, output_class)\n",
    "report = classification_report(answer_class, output_class)\n",
    "\n",
    "recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "fallout = cm[1][0] / (cm[1][0] + cm[1][1])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(answer_class, output_score[:, 1], pos_label=1.)\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, thresholds)(eer)\n",
    "\n",
    "print(report)\n",
    "print(cm)\n",
    "print(\"AUROC: %f\" %(roc_auc_score(answer_class, output_score[:, 1])))\n",
    "print(\"THRESH: \" , thresh)\n",
    "print('test_acc: ', len(output_class[np.equal(output_class, answer_class)]) / len(output_class))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPykDpKpzBavJLmF/+k9+Cn",
   "collapsed_sections": [],
   "mount_file_id": "1402Yotl5EV6I7ydoZjvC667pxYPhTEnO",
   "name": "tensor_dcmp_baseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
