{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EltwXFS-h0N"
   },
   "source": [
    "# Baseline Code for Deepfake Detection\n",
    "\n",
    "\n",
    "By Dongmin Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vfYll4q9Dqj"
   },
   "source": [
    "## Data Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2574,
     "status": "ok",
     "timestamp": 1594861880337,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "AkbZHQ3w_3TH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "physical_devices = tf.config.experimental.get_visible_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COfNhpEv6u5S"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGR = lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "TOTAL_DATA_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9626,
     "status": "ok",
     "timestamp": 1594861887408,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "TYD8hU74FOKe"
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20, \n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest',\n",
    "    validation_split = VALID_RATIO,\n",
    ")\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **data_gen_args,\n",
    "    preprocessing_function = BGR\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    preprocessing_function = BGR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM DIR\n",
      "REAL:  10000\n",
      "FAKE:  10000\n",
      "TOTAL:  20000\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "#path = \"/media/data1/hsm/FACE_FORENSICS_C40/DATA_FRAMES/\"\n",
    "path = \"./TK\"\n",
    "real_data_dir = os.path.join(path, 'REAL')\n",
    "fake_data_dir = os.path.join(path, 'FAKE', 'NeuralTextures')\n",
    "\n",
    "real_filenames = np.array([os.path.join('REAL', f) for f in os.listdir(real_data_dir)])\n",
    "fake_filenames = np.array([os.path.join('FAKE', 'NeuralTextures', f) for f in os.listdir(fake_data_dir)])\n",
    "\n",
    "print(\"FROM DIR\")\n",
    "print(\"REAL: \", len(real_filenames))\n",
    "print(\"FAKE: \", len(fake_filenames))\n",
    "print(\"TOTAL: \", len(real_filenames) + len(fake_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling\n",
    "real_filenames = np.random.choice(real_filenames, TOTAL_DATA_SIZE//2, replace = False).tolist()\n",
    "fake_filenames = np.random.choice(fake_filenames, TOTAL_DATA_SIZE//2, replace = False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIM SIZE\n",
      "REAL:  10000\n",
      "FAKE:  10000\n",
      "TOTAL:  20000\n",
      "TRAIN:  16200 VALIDATION:  1800 TEST:  2000\n"
     ]
    }
   ],
   "source": [
    "print(\"TRIM SIZE\")\n",
    "print(\"REAL: \", len(real_filenames))\n",
    "print(\"FAKE: \", len(fake_filenames))\n",
    "print(\"TOTAL: \", len(real_filenames) + len(fake_filenames))\n",
    "\n",
    "total_length = len(real_filenames) + len(fake_filenames)\n",
    "\n",
    "test_length = int(total_length * TEST_RATIO)\n",
    "validation_length = int((total_length-test_length) * VALID_RATIO)\n",
    "train_length = total_length - validation_length - test_length\n",
    "\n",
    "print(\"TRAIN: \", train_length, \"VALIDATION: \", validation_length, \"TEST: \", test_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_filenames_test = real_filenames[:test_length//2]\n",
    "fake_filenames_test = fake_filenames[:test_length//2]\n",
    "real_filenames = real_filenames[test_length//2:]\n",
    "fake_filenames = fake_filenames[test_length//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_categories_test = []\n",
    "for filename in real_filenames_test:\n",
    "    real_categories_test.append('0')\n",
    "        \n",
    "real_testdata = pd.DataFrame({'filename' : real_filenames_test, 'label' : real_categories_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_categories_test = []\n",
    "for filename in fake_filenames_test:\n",
    "    fake_categories_test.append('1')\n",
    "\n",
    "fake_testdata = pd.DataFrame({'filename' : fake_filenames_test, 'label' : fake_categories_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([real_testdata, fake_testdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real : 0, fake : 1\n",
    "categories = []\n",
    "for filename in real_filenames:\n",
    "    categories.append('0')\n",
    "    \n",
    "for filename in fake_filenames:\n",
    "    categories.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'filename' : real_filenames + fake_filenames, 'label' : categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/16__podium_speech_happy_frame1145.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/11__talking_against_wall_frame30.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/133_frame456.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/05__talking_against_wall_frame300.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/672_frame354.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>FAKE/NeuralTextures/211_177_frame120.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>FAKE/NeuralTextures/727_729_frame370.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>FAKE/NeuralTextures/314_347_frame318.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>FAKE/NeuralTextures/546_621_frame210.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>FAKE/NeuralTextures/743_750_frame144.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename label\n",
       "0      REAL/16__podium_speech_happy_frame1145.jpg     0\n",
       "1       REAL/11__talking_against_wall_frame30.jpg     0\n",
       "2                           REAL/133_frame456.jpg     0\n",
       "3      REAL/05__talking_against_wall_frame300.jpg     0\n",
       "4                           REAL/672_frame354.jpg     0\n",
       "...                                           ...   ...\n",
       "17995    FAKE/NeuralTextures/211_177_frame120.jpg     1\n",
       "17996    FAKE/NeuralTextures/727_729_frame370.jpg     1\n",
       "17997    FAKE/NeuralTextures/314_347_frame318.jpg     1\n",
       "17998    FAKE/NeuralTextures/546_621_frame210.jpg     1\n",
       "17999    FAKE/NeuralTextures/743_750_frame144.jpg     1\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[np.random.RandomState(seed = 42).permutation(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>REAL/794_frame430.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>REAL/540_frame170.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>FAKE/NeuralTextures/104_126_frame78.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>REAL/01__kitchen_still_frame250.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>REAL/241_frame210.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>FAKE/NeuralTextures/234_187_frame102.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>FAKE/NeuralTextures/118_120_frame125.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>REAL/744_frame84.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>REAL/074_frame35.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>FAKE/NeuralTextures/544_532_frame270.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename label\n",
       "2574                      REAL/794_frame430.jpg     0\n",
       "7496                      REAL/540_frame170.jpg     0\n",
       "9210    FAKE/NeuralTextures/104_126_frame78.jpg     1\n",
       "5456        REAL/01__kitchen_still_frame250.jpg     0\n",
       "736                       REAL/241_frame210.jpg     0\n",
       "...                                         ...   ...\n",
       "11284  FAKE/NeuralTextures/234_187_frame102.jpg     1\n",
       "11964  FAKE/NeuralTextures/118_120_frame125.jpg     1\n",
       "5390                       REAL/744_frame84.jpg     0\n",
       "860                        REAL/074_frame35.jpg     0\n",
       "15795  FAKE/NeuralTextures/544_532_frame270.jpg     1\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/07__talking_angry_couch_frame1500.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/385_frame72.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/06__walk_down_hall_angry_frame20.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/825_frame420.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/994_frame25.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>FAKE/NeuralTextures/949_868_frame72.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>FAKE/NeuralTextures/579_701_frame96.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>FAKE/NeuralTextures/271_264_frame90.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>FAKE/NeuralTextures/712_716_frame340.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>FAKE/NeuralTextures/359_317_frame294.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename label\n",
       "0    REAL/07__talking_angry_couch_frame1500.jpg     0\n",
       "1                          REAL/385_frame72.jpg     0\n",
       "2     REAL/06__walk_down_hall_angry_frame20.jpg     0\n",
       "3                         REAL/825_frame420.jpg     0\n",
       "4                          REAL/994_frame25.jpg     0\n",
       "..                                          ...   ...\n",
       "995     FAKE/NeuralTextures/949_868_frame72.jpg     1\n",
       "996     FAKE/NeuralTextures/579_701_frame96.jpg     1\n",
       "997     FAKE/NeuralTextures/271_264_frame90.jpg     1\n",
       "998    FAKE/NeuralTextures/712_716_frame340.jpg     1\n",
       "999    FAKE/NeuralTextures/359_317_frame294.jpg     1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1000\n",
       "1    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.groupby(['label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44421,
     "status": "ok",
     "timestamp": 1594861922212,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "JfDhCEOCHMP9",
    "outputId": "bf643961-e321-433e-84f8-7f793bd2efda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16200 validated image filenames belonging to 2 classes.\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "Found 2000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True,\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True,\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_data,\n",
    "    directory = path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size =(256, 256),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53852,
     "status": "ok",
     "timestamp": 1594861931663,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "Q7lrrsvnh0FO",
    "outputId": "763103a8-abec-4e65-91c0-fe6e1a91cf63"
   },
   "outputs": [],
   "source": [
    "# import available models for training\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Dropout\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53849,
     "status": "ok",
     "timestamp": 1594861931664,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "h_qQl7mYM_4H"
   },
   "outputs": [],
   "source": [
    "def setupmodel():\n",
    "    input_tensor = Input(shape = (256,256,3))\n",
    "\n",
    "    base_model = Xception(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_tensor = input_tensor\n",
    "    )\n",
    "    # Setup\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation = \"relu\")(x)\n",
    "    prediction = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # model return\n",
    "    model = Model(base_model.input, prediction)\n",
    "\n",
    "    # trainable\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57132,
     "status": "ok",
     "timestamp": 1594861934952,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "W72UW_JAOqIL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dongmin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = setupmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57125,
     "status": "ok",
     "timestamp": 1594861934955,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "w1aKA6TGPYQJ",
    "outputId": "d713b6a3-c474-4ff3-db93-246221cd12ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 63, 63, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 63, 63, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 63, 63, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 131072)       0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          33554688    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 54,416,425\n",
      "Trainable params: 54,361,897\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57122,
     "status": "ok",
     "timestamp": 1594861934956,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "g2uCmYuC_QFB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(tf.keras.callbacks.Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57119,
     "status": "ok",
     "timestamp": 1594861934957,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "Gg-pDKlNjjf1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, validation_generator, test_generator, optimizer):\n",
    "    # checkpointing\n",
    "    filename = 'checkpoint-TK-smalldata.h5'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                        filename, \n",
    "                        monitor='val_loss',\n",
    "                        verbose=1,           \n",
    "                        save_best_only=True,\n",
    "                        mode='auto'\n",
    "                )\n",
    "    # early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "    \n",
    "    # Cyclic Learning Rate\n",
    "    clr = CyclicLR(\n",
    "        base_lr=1e-3,#0.001, \n",
    "        max_lr=7e-3,#0.007,\n",
    "        step_size=300., \n",
    "        mode='exp_range',\n",
    "        gamma=0.99994\n",
    "    )\n",
    "    \n",
    "    # compile\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    # train\n",
    "    print(\"== Start Training ==\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = train_length // BATCH_SIZE, \n",
    "        epochs = EPOCHS,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = validation_length // BATCH_SIZE,\n",
    "        callbacks=[checkpoint, clr],\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8202582,
     "status": "ok",
     "timestamp": 1594870080429,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "JzhaoVTjPPw-",
    "outputId": "44580b4c-b6d8-45bb-c65e-ecf7a1ae9c12",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Start Training ==\n",
      "Epoch 1/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.7541 - accuracy: 0.5925\n",
      "Epoch 00001: val_loss improved from inf to 0.68947, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 376s 743ms/step - loss: 0.7540 - accuracy: 0.5923 - val_loss: 0.6895 - val_accuracy: 0.5458\n",
      "Epoch 2/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6599 - accuracy: 0.6115\n",
      "Epoch 00002: val_loss improved from 0.68947 to 0.64561, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 317s 627ms/step - loss: 0.6601 - accuracy: 0.6111 - val_loss: 0.6456 - val_accuracy: 0.6239\n",
      "Epoch 3/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.6231 - accuracy: 0.6384\n",
      "Epoch 00003: val_loss did not improve from 0.64561\n",
      "506/506 [==============================] - 317s 626ms/step - loss: 0.6231 - accuracy: 0.6384 - val_loss: 0.6820 - val_accuracy: 0.5887\n",
      "Epoch 4/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5954 - accuracy: 0.6720\n",
      "Epoch 00004: val_loss improved from 0.64561 to 0.61432, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 321s 634ms/step - loss: 0.5953 - accuracy: 0.6722 - val_loss: 0.6143 - val_accuracy: 0.6602\n",
      "Epoch 5/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5860 - accuracy: 0.6798\n",
      "Epoch 00005: val_loss improved from 0.61432 to 0.59833, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 318s 629ms/step - loss: 0.5862 - accuracy: 0.6797 - val_loss: 0.5983 - val_accuracy: 0.6819\n",
      "Epoch 6/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5847 - accuracy: 0.6840\n",
      "Epoch 00006: val_loss improved from 0.59833 to 0.56913, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 319s 629ms/step - loss: 0.5849 - accuracy: 0.6840 - val_loss: 0.5691 - val_accuracy: 0.7003\n",
      "Epoch 7/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.6935\n",
      "Epoch 00007: val_loss improved from 0.56913 to 0.54411, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 315s 623ms/step - loss: 0.5729 - accuracy: 0.6934 - val_loss: 0.5441 - val_accuracy: 0.7081\n",
      "Epoch 8/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5591 - accuracy: 0.7023\n",
      "Epoch 00008: val_loss did not improve from 0.54411\n",
      "506/506 [==============================] - 314s 620ms/step - loss: 0.5590 - accuracy: 0.7024 - val_loss: 0.8011 - val_accuracy: 0.6004\n",
      "Epoch 9/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5473 - accuracy: 0.7155\n",
      "Epoch 00009: val_loss did not improve from 0.54411\n",
      "506/506 [==============================] - 314s 620ms/step - loss: 0.5472 - accuracy: 0.7155 - val_loss: 0.6266 - val_accuracy: 0.6456\n",
      "Epoch 10/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.7167\n",
      "Epoch 00010: val_loss did not improve from 0.54411\n",
      "506/506 [==============================] - 318s 629ms/step - loss: 0.5404 - accuracy: 0.7169 - val_loss: 0.5874 - val_accuracy: 0.6992\n",
      "Epoch 11/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5294 - accuracy: 0.7260\n",
      "Epoch 00011: val_loss did not improve from 0.54411\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.5294 - accuracy: 0.7260 - val_loss: 0.5718 - val_accuracy: 0.6897\n",
      "Epoch 12/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.7245\n",
      "Epoch 00012: val_loss improved from 0.54411 to 0.51966, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 317s 627ms/step - loss: 0.5346 - accuracy: 0.7245 - val_loss: 0.5197 - val_accuracy: 0.7132\n",
      "Epoch 13/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5235 - accuracy: 0.7321\n",
      "Epoch 00013: val_loss did not improve from 0.51966\n",
      "506/506 [==============================] - 314s 621ms/step - loss: 0.5235 - accuracy: 0.7320 - val_loss: 0.5390 - val_accuracy: 0.7271\n",
      "Epoch 14/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5170 - accuracy: 0.7326\n",
      "Epoch 00014: val_loss did not improve from 0.51966\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.5172 - accuracy: 0.7326 - val_loss: 0.6275 - val_accuracy: 0.6618\n",
      "Epoch 15/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.7369\n",
      "Epoch 00015: val_loss did not improve from 0.51966\n",
      "506/506 [==============================] - 313s 618ms/step - loss: 0.5216 - accuracy: 0.7368 - val_loss: 1.3188 - val_accuracy: 0.6021\n",
      "Epoch 16/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.7353\n",
      "Epoch 00016: val_loss did not improve from 0.51966\n",
      "506/506 [==============================] - 313s 618ms/step - loss: 0.5244 - accuracy: 0.7352 - val_loss: 0.9291 - val_accuracy: 0.6914\n",
      "Epoch 17/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4973 - accuracy: 0.7509\n",
      "Epoch 00017: val_loss did not improve from 0.51966\n",
      "506/506 [==============================] - 310s 613ms/step - loss: 0.4972 - accuracy: 0.7510 - val_loss: 0.5354 - val_accuracy: 0.7282\n",
      "Epoch 18/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4984 - accuracy: 0.7484\n",
      "Epoch 00018: val_loss improved from 0.51966 to 0.49175, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 313s 618ms/step - loss: 0.4981 - accuracy: 0.7487 - val_loss: 0.4918 - val_accuracy: 0.7483\n",
      "Epoch 19/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4894 - accuracy: 0.7561\n",
      "Epoch 00019: val_loss improved from 0.49175 to 0.47630, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 321s 634ms/step - loss: 0.4894 - accuracy: 0.7561 - val_loss: 0.4763 - val_accuracy: 0.7533\n",
      "Epoch 20/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4878 - accuracy: 0.7590\n",
      "Epoch 00020: val_loss did not improve from 0.47630\n",
      "506/506 [==============================] - 316s 625ms/step - loss: 0.4878 - accuracy: 0.7590 - val_loss: 0.5346 - val_accuracy: 0.7015\n",
      "Epoch 21/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.7703\n",
      "Epoch 00021: val_loss did not improve from 0.47630\n",
      "506/506 [==============================] - 316s 625ms/step - loss: 0.4689 - accuracy: 0.7702 - val_loss: 0.4991 - val_accuracy: 0.7433\n",
      "Epoch 22/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.7832\n",
      "Epoch 00022: val_loss did not improve from 0.47630\n",
      "506/506 [==============================] - 308s 609ms/step - loss: 0.4511 - accuracy: 0.7828 - val_loss: 0.6782 - val_accuracy: 0.6842\n",
      "Epoch 23/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4651 - accuracy: 0.7752\n",
      "Epoch 00023: val_loss did not improve from 0.47630\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.4651 - accuracy: 0.7752 - val_loss: 0.4784 - val_accuracy: 0.7584\n",
      "Epoch 24/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.7811\n",
      "Epoch 00024: val_loss improved from 0.47630 to 0.47620, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 317s 626ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.4762 - val_accuracy: 0.7684\n",
      "Epoch 25/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.7750\n",
      "Epoch 00025: val_loss improved from 0.47620 to 0.46164, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.4680 - accuracy: 0.7749 - val_loss: 0.4616 - val_accuracy: 0.7679\n",
      "Epoch 26/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4412 - accuracy: 0.7905\n",
      "Epoch 00026: val_loss did not improve from 0.46164\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.4414 - accuracy: 0.7903 - val_loss: 0.4673 - val_accuracy: 0.7695\n",
      "Epoch 27/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4205 - accuracy: 0.8020\n",
      "Epoch 00027: val_loss did not improve from 0.46164\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.6602 - val_accuracy: 0.7388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.8140\n",
      "Epoch 00028: val_loss did not improve from 0.46164\n",
      "506/506 [==============================] - 315s 622ms/step - loss: 0.4000 - accuracy: 0.8141 - val_loss: 0.6921 - val_accuracy: 0.7204\n",
      "Epoch 29/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8157\n",
      "Epoch 00029: val_loss did not improve from 0.46164\n",
      "506/506 [==============================] - 318s 628ms/step - loss: 0.3912 - accuracy: 0.8156 - val_loss: 0.5218 - val_accuracy: 0.7612\n",
      "Epoch 30/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8233\n",
      "Epoch 00030: val_loss improved from 0.46164 to 0.43703, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 319s 631ms/step - loss: 0.3871 - accuracy: 0.8234 - val_loss: 0.4370 - val_accuracy: 0.7868\n",
      "Epoch 31/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3737 - accuracy: 0.8291\n",
      "Epoch 00031: val_loss did not improve from 0.43703\n",
      "506/506 [==============================] - 318s 629ms/step - loss: 0.3740 - accuracy: 0.8290 - val_loss: 0.4763 - val_accuracy: 0.7863\n",
      "Epoch 32/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3640 - accuracy: 0.8357\n",
      "Epoch 00032: val_loss improved from 0.43703 to 0.40368, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 315s 623ms/step - loss: 0.3640 - accuracy: 0.8357 - val_loss: 0.4037 - val_accuracy: 0.8092\n",
      "Epoch 33/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.8375\n",
      "Epoch 00033: val_loss did not improve from 0.40368\n",
      "506/506 [==============================] - 313s 618ms/step - loss: 0.3538 - accuracy: 0.8376 - val_loss: 0.4779 - val_accuracy: 0.7896\n",
      "Epoch 34/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.8443\n",
      "Epoch 00034: val_loss did not improve from 0.40368\n",
      "506/506 [==============================] - 313s 619ms/step - loss: 0.3407 - accuracy: 0.8438 - val_loss: 0.6017 - val_accuracy: 0.7506\n",
      "Epoch 35/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3286 - accuracy: 0.8544\n",
      "Epoch 00035: val_loss did not improve from 0.40368\n",
      "506/506 [==============================] - 319s 631ms/step - loss: 0.3288 - accuracy: 0.8545 - val_loss: 0.4648 - val_accuracy: 0.7656\n",
      "Epoch 36/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8648\n",
      "Epoch 00036: val_loss did not improve from 0.40368\n",
      "506/506 [==============================] - 319s 630ms/step - loss: 0.3107 - accuracy: 0.8650 - val_loss: 0.4548 - val_accuracy: 0.7812\n",
      "Epoch 37/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.8667\n",
      "Epoch 00037: val_loss did not improve from 0.40368\n",
      "506/506 [==============================] - 321s 633ms/step - loss: 0.3044 - accuracy: 0.8666 - val_loss: 0.5043 - val_accuracy: 0.7963\n",
      "Epoch 38/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.8721\n",
      "Epoch 00038: val_loss improved from 0.40368 to 0.38324, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 326s 644ms/step - loss: 0.2979 - accuracy: 0.8723 - val_loss: 0.3832 - val_accuracy: 0.8410\n",
      "Epoch 39/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2886 - accuracy: 0.8761\n",
      "Epoch 00039: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 323s 639ms/step - loss: 0.2883 - accuracy: 0.8763 - val_loss: 0.3988 - val_accuracy: 0.8225\n",
      "Epoch 40/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.8828\n",
      "Epoch 00040: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 317s 627ms/step - loss: 0.2730 - accuracy: 0.8829 - val_loss: 0.4431 - val_accuracy: 0.8064\n",
      "Epoch 41/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.8922\n",
      "Epoch 00041: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 320s 633ms/step - loss: 0.2543 - accuracy: 0.8921 - val_loss: 0.4616 - val_accuracy: 0.8013\n",
      "Epoch 42/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.8970\n",
      "Epoch 00042: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 318s 629ms/step - loss: 0.2452 - accuracy: 0.8970 - val_loss: 0.4117 - val_accuracy: 0.8287\n",
      "Epoch 43/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.8981\n",
      "Epoch 00043: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 319s 631ms/step - loss: 0.2442 - accuracy: 0.8980 - val_loss: 0.4246 - val_accuracy: 0.8281\n",
      "Epoch 44/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.3103 - accuracy: 0.8694\n",
      "Epoch 00044: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 322s 636ms/step - loss: 0.3102 - accuracy: 0.8694 - val_loss: 0.4316 - val_accuracy: 0.8136\n",
      "Epoch 45/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.8969\n",
      "Epoch 00045: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 312s 617ms/step - loss: 0.2503 - accuracy: 0.8970 - val_loss: 0.5011 - val_accuracy: 0.7963\n",
      "Epoch 46/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9054\n",
      "Epoch 00046: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 604ms/step - loss: 0.2267 - accuracy: 0.9054 - val_loss: 0.4369 - val_accuracy: 0.8242\n",
      "Epoch 47/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.2059 - accuracy: 0.9150\n",
      "Epoch 00047: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 601ms/step - loss: 0.2058 - accuracy: 0.9151 - val_loss: 0.5768 - val_accuracy: 0.8013\n",
      "Epoch 48/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.9234\n",
      "Epoch 00048: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 303s 598ms/step - loss: 0.1869 - accuracy: 0.9234 - val_loss: 0.6724 - val_accuracy: 0.7863\n",
      "Epoch 49/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9207\n",
      "Epoch 00049: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 604ms/step - loss: 0.1894 - accuracy: 0.9207 - val_loss: 0.4287 - val_accuracy: 0.8343\n",
      "Epoch 50/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9283\n",
      "Epoch 00050: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 605ms/step - loss: 0.1794 - accuracy: 0.9284 - val_loss: 0.4047 - val_accuracy: 0.8544\n",
      "Epoch 51/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9276\n",
      "Epoch 00051: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 300s 594ms/step - loss: 0.1810 - accuracy: 0.9275 - val_loss: 0.4587 - val_accuracy: 0.8298\n",
      "Epoch 52/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9352\n",
      "Epoch 00052: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 601ms/step - loss: 0.1638 - accuracy: 0.9353 - val_loss: 0.4239 - val_accuracy: 0.8432\n",
      "Epoch 53/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9377\n",
      "Epoch 00053: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.1594 - accuracy: 0.9378 - val_loss: 0.4661 - val_accuracy: 0.8270\n",
      "Epoch 54/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9418\n",
      "Epoch 00054: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 315s 622ms/step - loss: 0.1465 - accuracy: 0.9419 - val_loss: 0.4138 - val_accuracy: 0.8298\n",
      "Epoch 55/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9432\n",
      "Epoch 00055: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 307s 607ms/step - loss: 0.1439 - accuracy: 0.9432 - val_loss: 0.5974 - val_accuracy: 0.7785\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/506 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 0.9447\n",
      "Epoch 00056: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 606ms/step - loss: 0.1377 - accuracy: 0.9446 - val_loss: 0.4443 - val_accuracy: 0.8415\n",
      "Epoch 57/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9450\n",
      "Epoch 00057: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.1405 - accuracy: 0.9450 - val_loss: 0.4503 - val_accuracy: 0.8504\n",
      "Epoch 58/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9478\n",
      "Epoch 00058: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 601ms/step - loss: 0.1322 - accuracy: 0.9478 - val_loss: 0.4405 - val_accuracy: 0.8577\n",
      "Epoch 59/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9514\n",
      "Epoch 00059: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 601ms/step - loss: 0.1258 - accuracy: 0.9514 - val_loss: 0.5614 - val_accuracy: 0.8499\n",
      "Epoch 60/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9563\n",
      "Epoch 00060: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 602ms/step - loss: 0.1150 - accuracy: 0.9562 - val_loss: 0.6945 - val_accuracy: 0.7919\n",
      "Epoch 61/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9562\n",
      "Epoch 00061: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 603ms/step - loss: 0.1108 - accuracy: 0.9561 - val_loss: 0.4221 - val_accuracy: 0.8544\n",
      "Epoch 62/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9572\n",
      "Epoch 00062: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 307s 607ms/step - loss: 0.1102 - accuracy: 0.9571 - val_loss: 0.4244 - val_accuracy: 0.8583\n",
      "Epoch 63/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1079 - accuracy: 0.9582\n",
      "Epoch 00063: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.1080 - accuracy: 0.9581 - val_loss: 0.4577 - val_accuracy: 0.8555\n",
      "Epoch 64/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.9584\n",
      "Epoch 00064: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 604ms/step - loss: 0.1077 - accuracy: 0.9583 - val_loss: 0.4638 - val_accuracy: 0.8510\n",
      "Epoch 65/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9648\n",
      "Epoch 00065: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 303s 599ms/step - loss: 0.0938 - accuracy: 0.9648 - val_loss: 0.4555 - val_accuracy: 0.8577\n",
      "Epoch 66/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9655\n",
      "Epoch 00066: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 302s 597ms/step - loss: 0.0930 - accuracy: 0.9655 - val_loss: 0.4693 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0868 - accuracy: 0.9671\n",
      "Epoch 00067: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 301s 595ms/step - loss: 0.0867 - accuracy: 0.9671 - val_loss: 0.5102 - val_accuracy: 0.8555\n",
      "Epoch 68/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.9629\n",
      "Epoch 00068: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.0971 - accuracy: 0.9629 - val_loss: 0.5856 - val_accuracy: 0.8404\n",
      "Epoch 69/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9676\n",
      "Epoch 00069: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 303s 599ms/step - loss: 0.0838 - accuracy: 0.9677 - val_loss: 0.5243 - val_accuracy: 0.8555\n",
      "Epoch 70/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 0.9691\n",
      "Epoch 00070: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 602ms/step - loss: 0.0848 - accuracy: 0.9691 - val_loss: 0.4350 - val_accuracy: 0.8599\n",
      "Epoch 71/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9690\n",
      "Epoch 00071: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 603ms/step - loss: 0.0817 - accuracy: 0.9690 - val_loss: 0.5274 - val_accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0775 - accuracy: 0.9716\n",
      "Epoch 00072: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 303s 599ms/step - loss: 0.0773 - accuracy: 0.9716 - val_loss: 0.7675 - val_accuracy: 0.8231\n",
      "Epoch 73/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9721\n",
      "Epoch 00073: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 606ms/step - loss: 0.0761 - accuracy: 0.9721 - val_loss: 0.4428 - val_accuracy: 0.8616\n",
      "Epoch 74/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9710\n",
      "Epoch 00074: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 602ms/step - loss: 0.0763 - accuracy: 0.9710 - val_loss: 0.4688 - val_accuracy: 0.8410\n",
      "Epoch 75/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9729\n",
      "Epoch 00075: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 602ms/step - loss: 0.0720 - accuracy: 0.9729 - val_loss: 0.5586 - val_accuracy: 0.8454\n",
      "Epoch 76/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9754\n",
      "Epoch 00076: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 601ms/step - loss: 0.0696 - accuracy: 0.9753 - val_loss: 0.4792 - val_accuracy: 0.8644\n",
      "Epoch 77/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 0.9734\n",
      "Epoch 00077: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 605ms/step - loss: 0.0727 - accuracy: 0.9733 - val_loss: 0.4178 - val_accuracy: 0.8689\n",
      "Epoch 78/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9744\n",
      "Epoch 00078: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 603ms/step - loss: 0.0704 - accuracy: 0.9743 - val_loss: 0.4912 - val_accuracy: 0.8443\n",
      "Epoch 79/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 0.9774\n",
      "Epoch 00079: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 0.4207 - val_accuracy: 0.8683\n",
      "Epoch 80/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9763\n",
      "Epoch 00080: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 605ms/step - loss: 0.0641 - accuracy: 0.9763 - val_loss: 0.4579 - val_accuracy: 0.8538\n",
      "Epoch 81/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9789\n",
      "Epoch 00081: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 604ms/step - loss: 0.0588 - accuracy: 0.9788 - val_loss: 0.5861 - val_accuracy: 0.8544\n",
      "Epoch 82/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9748\n",
      "Epoch 00082: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 302s 597ms/step - loss: 0.0646 - accuracy: 0.9747 - val_loss: 0.5419 - val_accuracy: 0.8616\n",
      "Epoch 83/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9747\n",
      "Epoch 00083: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 303s 598ms/step - loss: 0.0629 - accuracy: 0.9747 - val_loss: 0.4926 - val_accuracy: 0.8733\n",
      "Epoch 84/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9792\n",
      "Epoch 00084: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 605ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 0.6653 - val_accuracy: 0.8471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9774\n",
      "Epoch 00085: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.0626 - accuracy: 0.9775 - val_loss: 0.5187 - val_accuracy: 0.8677\n",
      "Epoch 86/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9830\n",
      "Epoch 00086: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 603ms/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 0.5555 - val_accuracy: 0.8638\n",
      "Epoch 87/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9798\n",
      "Epoch 00087: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 305s 602ms/step - loss: 0.0553 - accuracy: 0.9798 - val_loss: 0.5080 - val_accuracy: 0.8795\n",
      "Epoch 88/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9805\n",
      "Epoch 00088: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 306s 604ms/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 0.6854 - val_accuracy: 0.8510\n",
      "Epoch 89/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9815\n",
      "Epoch 00089: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 601ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 0.5408 - val_accuracy: 0.8661\n",
      "Epoch 90/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9790\n",
      "Epoch 00090: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 303s 599ms/step - loss: 0.0601 - accuracy: 0.9789 - val_loss: 0.4397 - val_accuracy: 0.8605\n",
      "Epoch 91/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9825\n",
      "Epoch 00091: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 0.5207 - val_accuracy: 0.8689\n",
      "Epoch 92/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9838\n",
      "Epoch 00092: val_loss did not improve from 0.38324\n",
      "506/506 [==============================] - 303s 598ms/step - loss: 0.0464 - accuracy: 0.9837 - val_loss: 0.4704 - val_accuracy: 0.8605\n",
      "Epoch 93/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9834\n",
      "Epoch 00093: val_loss improved from 0.38324 to 0.37726, saving model to checkpoint-TK-smalldata.h5\n",
      "506/506 [==============================] - 307s 607ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.3773 - val_accuracy: 0.8683\n",
      "Epoch 94/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9824\n",
      "Epoch 00094: val_loss did not improve from 0.37726\n",
      "506/506 [==============================] - 305s 603ms/step - loss: 0.0476 - accuracy: 0.9824 - val_loss: 0.5769 - val_accuracy: 0.8588\n",
      "Epoch 95/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9839\n",
      "Epoch 00095: val_loss did not improve from 0.37726\n",
      "506/506 [==============================] - 302s 596ms/step - loss: 0.0444 - accuracy: 0.9839 - val_loss: 0.4658 - val_accuracy: 0.8811\n",
      "Epoch 96/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9836\n",
      "Epoch 00096: val_loss did not improve from 0.37726\n",
      "506/506 [==============================] - 305s 604ms/step - loss: 0.0454 - accuracy: 0.9836 - val_loss: 0.4683 - val_accuracy: 0.8733\n",
      "Epoch 97/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9839\n",
      "Epoch 00097: val_loss did not improve from 0.37726\n",
      "506/506 [==============================] - 304s 601ms/step - loss: 0.0448 - accuracy: 0.9840 - val_loss: 0.5205 - val_accuracy: 0.8605\n",
      "Epoch 98/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9826\n",
      "Epoch 00098: val_loss did not improve from 0.37726\n",
      "506/506 [==============================] - 303s 598ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 0.5827 - val_accuracy: 0.8605\n",
      "Epoch 99/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9830\n",
      "Epoch 00099: val_loss did not improve from 0.37726\n",
      "506/506 [==============================] - 304s 600ms/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 0.5095 - val_accuracy: 0.8527\n",
      "Epoch 100/100\n",
      "505/506 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9867\n",
      "Epoch 00100: val_loss did not improve from 0.37726\n",
      "506/506 [==============================] - 305s 603ms/step - loss: 0.0375 - accuracy: 0.9867 - val_loss: 0.5292 - val_accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, train_generator, validation_generator, test_generator, tf.keras.optimizers.Adam(lr = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOGQG83odP4U"
   },
   "source": [
    "**Plot Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8202586,
     "status": "ok",
     "timestamp": 1594870080436,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "g2oyNk4PRDmG",
    "outputId": "37e2d458-be48-47de-f275-fe3e0f6901a7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8203098,
     "status": "ok",
     "timestamp": 1594870080952,
     "user": {
      "displayName": "dongmin kim",
      "photoUrl": "",
      "userId": "18288781491500504816"
     },
     "user_tz": -540
    },
    "id": "dFJLAzliRFJz",
    "outputId": "bc985298-1c87-45f4-a361-574ed5ba99ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setupmodel()\n",
    "json_filename = \"TK_model.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(json_filename, \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json \n",
    "json_file = open(json_filename, \"r\") \n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close() \n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "loaded_model.load_weights(\"checkpoint-TK-smalldata.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics - F1, Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Evaluate ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:17<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.91522741e-02 9.70847726e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99970943e-01 2.90572643e-05]\n",
      " [9.91388381e-01 8.61161947e-03]\n",
      " [1.00000000e+00 0.00000000e+00]]\n",
      "[1. 0. 0. ... 0. 1. 0.]\n",
      "[1 0 0 ... 0 0 0]\n",
      "[1. 0. 0. ... 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"== Evaluate ==\")\n",
    "\n",
    "output_score = []\n",
    "output_class = []\n",
    "answer_class = []\n",
    "\n",
    "for i in trange(len(test_generator)):\n",
    "    output = loaded_model.predict_on_batch(test_generator[i][0])\n",
    "    output_score.append(output)\n",
    "    answer_class.append(test_generator[i][1])\n",
    "    \n",
    "output_score = np.concatenate(output_score)\n",
    "answer_class = np.concatenate(answer_class)\n",
    "\n",
    "lst = []\n",
    "for i in output_score:\n",
    "    val = i[0]\n",
    "    sublst = [1-val, val]\n",
    "    lst.append(sublst)\n",
    "    \n",
    "output_score = np.array(lst)\n",
    "\n",
    "print(output_score)\n",
    "print(answer_class)\n",
    "\n",
    "output_class = np.argmax(output_score, axis=1)\n",
    "\n",
    "print(output_class)\n",
    "print(answer_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1000.0\n",
      "2000\n",
      "773\n"
     ]
    }
   ],
   "source": [
    "print(len(answer_class))\n",
    "\n",
    "cnt = np.sum(answer_class)\n",
    "print(cnt)\n",
    "\n",
    "print(len(output_class))\n",
    "cnt2= np.sum(output_class)\n",
    "print(cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.94      0.85      1000\n",
      "         1.0       0.92      0.71      0.81      1000\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.85      0.83      0.83      2000\n",
      "weighted avg       0.85      0.83      0.83      2000\n",
      "\n",
      "[[942  58]\n",
      " [285 715]]\n",
      "AUROC: 0.940521\n",
      "THRESH:  0.051679372788021906\n",
      "test_acc:  0.8285\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(answer_class, output_class)\n",
    "report = classification_report(answer_class, output_class)\n",
    "\n",
    "recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "fallout = cm[1][0] / (cm[1][0] + cm[1][1])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(answer_class, output_score[:, 1], pos_label=1.)\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, thresholds)(eer)\n",
    "\n",
    "print(report)\n",
    "print(cm)\n",
    "print(\"AUROC: %f\" %(roc_auc_score(answer_class, output_score[:, 1])))\n",
    "print(\"THRESH: \" , thresh)\n",
    "print('test_acc: ', len(output_class[np.equal(output_class, answer_class)]) / len(output_class))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPykDpKpzBavJLmF/+k9+Cn",
   "collapsed_sections": [],
   "mount_file_id": "1402Yotl5EV6I7ydoZjvC667pxYPhTEnO",
   "name": "tensor_dcmp_baseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
